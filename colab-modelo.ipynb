{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KdBbTIKE6U5d",
        "outputId": "67765e67-fa8b-4bf3-9b67-841f799b5ddf"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'models'...\n",
            "remote: Enumerating objects: 97142, done.\u001b[K\n",
            "remote: Counting objects: 100% (422/422), done.\u001b[K\n",
            "remote: Compressing objects: 100% (196/196), done.\u001b[K\n",
            "remote: Total 97142 (delta 243), reused 374 (delta 225), pack-reused 96720\u001b[K\n",
            "Receiving objects: 100% (97142/97142), 612.85 MiB | 23.84 MiB/s, done.\n",
            "Resolving deltas: 100% (70655/70655), done.\n",
            "/content/models/research\n",
            "Processing /content/models/research\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting avro-python3 (from object-detection==0.1)\n",
            "  Downloading avro-python3-1.10.2.tar.gz (38 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting apache-beam (from object-detection==0.1)\n",
            "  Downloading apache_beam-2.55.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (14.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m14.8/14.8 MB\u001b[0m \u001b[31m61.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pillow in /usr/local/lib/python3.10/dist-packages (from object-detection==0.1) (9.4.0)\n",
            "Requirement already satisfied: lxml in /usr/local/lib/python3.10/dist-packages (from object-detection==0.1) (4.9.4)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (from object-detection==0.1) (3.7.1)\n",
            "Requirement already satisfied: Cython in /usr/local/lib/python3.10/dist-packages (from object-detection==0.1) (3.0.10)\n",
            "Requirement already satisfied: contextlib2 in /usr/local/lib/python3.10/dist-packages (from object-detection==0.1) (21.6.0)\n",
            "Requirement already satisfied: tf-slim in /usr/local/lib/python3.10/dist-packages (from object-detection==0.1) (1.1.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from object-detection==0.1) (1.16.0)\n",
            "Requirement already satisfied: pycocotools in /usr/local/lib/python3.10/dist-packages (from object-detection==0.1) (2.0.7)\n",
            "Collecting lvis (from object-detection==0.1)\n",
            "  Downloading lvis-0.5.3-py3-none-any.whl (14 kB)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from object-detection==0.1) (1.11.4)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from object-detection==0.1) (2.0.3)\n",
            "Collecting tf-models-official>=2.5.1 (from object-detection==0.1)\n",
            "  Downloading tf_models_official-2.16.0-py2.py3-none-any.whl (2.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.7/2.7 MB\u001b[0m \u001b[31m65.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting tensorflow_io (from object-detection==0.1)\n",
            "  Downloading tensorflow_io-0.36.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (49.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.4/49.4 MB\u001b[0m \u001b[31m9.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: keras in /usr/local/lib/python3.10/dist-packages (from object-detection==0.1) (2.15.0)\n",
            "Collecting pyparsing==2.4.7 (from object-detection==0.1)\n",
            "  Downloading pyparsing-2.4.7-py2.py3-none-any.whl (67 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m67.8/67.8 kB\u001b[0m \u001b[31m4.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting sacrebleu<=2.2.0 (from object-detection==0.1)\n",
            "  Downloading sacrebleu-2.2.0-py3-none-any.whl (116 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m116.6/116.6 kB\u001b[0m \u001b[31m12.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting portalocker (from sacrebleu<=2.2.0->object-detection==0.1)\n",
            "  Downloading portalocker-2.8.2-py3-none-any.whl (17 kB)\n",
            "Requirement already satisfied: regex in /usr/local/lib/python3.10/dist-packages (from sacrebleu<=2.2.0->object-detection==0.1) (2023.12.25)\n",
            "Requirement already satisfied: tabulate>=0.8.9 in /usr/local/lib/python3.10/dist-packages (from sacrebleu<=2.2.0->object-detection==0.1) (0.9.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from sacrebleu<=2.2.0->object-detection==0.1) (1.25.2)\n",
            "Collecting colorama (from sacrebleu<=2.2.0->object-detection==0.1)\n",
            "  Downloading colorama-0.4.6-py2.py3-none-any.whl (25 kB)\n",
            "Requirement already satisfied: gin-config in /usr/local/lib/python3.10/dist-packages (from tf-models-official>=2.5.1->object-detection==0.1) (0.5.0)\n",
            "Requirement already satisfied: google-api-python-client>=1.6.7 in /usr/local/lib/python3.10/dist-packages (from tf-models-official>=2.5.1->object-detection==0.1) (2.84.0)\n",
            "Collecting immutabledict (from tf-models-official>=2.5.1->object-detection==0.1)\n",
            "  Downloading immutabledict-4.2.0-py3-none-any.whl (4.7 kB)\n",
            "Requirement already satisfied: kaggle>=1.3.9 in /usr/local/lib/python3.10/dist-packages (from tf-models-official>=2.5.1->object-detection==0.1) (1.5.16)\n",
            "Requirement already satisfied: oauth2client in /usr/local/lib/python3.10/dist-packages (from tf-models-official>=2.5.1->object-detection==0.1) (4.1.3)\n",
            "Requirement already satisfied: opencv-python-headless in /usr/local/lib/python3.10/dist-packages (from tf-models-official>=2.5.1->object-detection==0.1) (4.9.0.80)\n",
            "Requirement already satisfied: psutil>=5.4.3 in /usr/local/lib/python3.10/dist-packages (from tf-models-official>=2.5.1->object-detection==0.1) (5.9.5)\n",
            "Requirement already satisfied: py-cpuinfo>=3.3.0 in /usr/local/lib/python3.10/dist-packages (from tf-models-official>=2.5.1->object-detection==0.1) (9.0.0)\n",
            "Requirement already satisfied: pyyaml>=6.0.0 in /usr/local/lib/python3.10/dist-packages (from tf-models-official>=2.5.1->object-detection==0.1) (6.0.1)\n",
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.10/dist-packages (from tf-models-official>=2.5.1->object-detection==0.1) (0.1.99)\n",
            "Collecting seqeval (from tf-models-official>=2.5.1->object-detection==0.1)\n",
            "  Downloading seqeval-1.2.2.tar.gz (43 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.6/43.6 kB\u001b[0m \u001b[31m6.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: tensorflow-datasets in /usr/local/lib/python3.10/dist-packages (from tf-models-official>=2.5.1->object-detection==0.1) (4.9.4)\n",
            "Requirement already satisfied: tensorflow-hub>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from tf-models-official>=2.5.1->object-detection==0.1) (0.16.1)\n",
            "Collecting tensorflow-model-optimization>=0.4.1 (from tf-models-official>=2.5.1->object-detection==0.1)\n",
            "  Downloading tensorflow_model_optimization-0.8.0-py2.py3-none-any.whl (242 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m242.5/242.5 kB\u001b[0m \u001b[31m22.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting tensorflow-text~=2.16.1 (from tf-models-official>=2.5.1->object-detection==0.1)\n",
            "  Downloading tensorflow_text-2.16.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (5.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.2/5.2 MB\u001b[0m \u001b[31m72.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting tensorflow~=2.16.1 (from tf-models-official>=2.5.1->object-detection==0.1)\n",
            "  Downloading tensorflow-2.16.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (589.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m589.8/589.8 MB\u001b[0m \u001b[31m1.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting tf-keras>=2.16.0 (from tf-models-official>=2.5.1->object-detection==0.1)\n",
            "  Downloading tf_keras-2.16.0-py3-none-any.whl (1.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m69.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->object-detection==0.1) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->object-detection==0.1) (2023.4)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas->object-detection==0.1) (2024.1)\n",
            "Requirement already satisfied: absl-py>=0.2.2 in /usr/local/lib/python3.10/dist-packages (from tf-slim->object-detection==0.1) (1.4.0)\n",
            "Collecting crcmod<2.0,>=1.7 (from apache-beam->object-detection==0.1)\n",
            "  Downloading crcmod-1.7.tar.gz (89 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m89.7/89.7 kB\u001b[0m \u001b[31m11.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting orjson<4,>=3.9.7 (from apache-beam->object-detection==0.1)\n",
            "  Downloading orjson-3.10.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (141 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m141.1/141.1 kB\u001b[0m \u001b[31m16.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting dill<0.3.2,>=0.3.1.1 (from apache-beam->object-detection==0.1)\n",
            "  Downloading dill-0.3.1.1.tar.gz (151 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m152.0/152.0 kB\u001b[0m \u001b[31m16.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: cloudpickle~=2.2.1 in /usr/local/lib/python3.10/dist-packages (from apache-beam->object-detection==0.1) (2.2.1)\n",
            "Collecting fastavro<2,>=0.23.6 (from apache-beam->object-detection==0.1)\n",
            "  Downloading fastavro-1.9.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.1/3.1 MB\u001b[0m \u001b[31m64.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting fasteners<1.0,>=0.3 (from apache-beam->object-detection==0.1)\n",
            "  Downloading fasteners-0.19-py3-none-any.whl (18 kB)\n",
            "Requirement already satisfied: grpcio!=1.48.0,<2,>=1.33.1 in /usr/local/lib/python3.10/dist-packages (from apache-beam->object-detection==0.1) (1.62.2)\n",
            "Collecting hdfs<3.0.0,>=2.1.0 (from apache-beam->object-detection==0.1)\n",
            "  Downloading hdfs-2.7.3.tar.gz (43 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.5/43.5 kB\u001b[0m \u001b[31m4.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: httplib2<0.23.0,>=0.8 in /usr/local/lib/python3.10/dist-packages (from apache-beam->object-detection==0.1) (0.22.0)\n",
            "Collecting js2py<1,>=0.74 (from apache-beam->object-detection==0.1)\n",
            "  Downloading Js2Py-0.74-py3-none-any.whl (1.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m70.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: jsonschema<5.0.0,>=4.0.0 in /usr/local/lib/python3.10/dist-packages (from apache-beam->object-detection==0.1) (4.19.2)\n",
            "Requirement already satisfied: jsonpickle<4.0.0,>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from apache-beam->object-detection==0.1) (3.0.4)\n",
            "Collecting objsize<0.8.0,>=0.6.1 (from apache-beam->object-detection==0.1)\n",
            "  Downloading objsize-0.7.0-py3-none-any.whl (11 kB)\n",
            "Requirement already satisfied: packaging>=22.0 in /usr/local/lib/python3.10/dist-packages (from apache-beam->object-detection==0.1) (24.0)\n",
            "Collecting pymongo<5.0.0,>=3.8.0 (from apache-beam->object-detection==0.1)\n",
            "  Downloading pymongo-4.7.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (670 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m670.1/670.1 kB\u001b[0m \u001b[31m49.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: proto-plus<2,>=1.7.1 in /usr/local/lib/python3.10/dist-packages (from apache-beam->object-detection==0.1) (1.23.0)\n",
            "Requirement already satisfied: protobuf!=4.0.*,!=4.21.*,!=4.22.0,!=4.23.*,!=4.24.*,<4.26.0,>=3.20.3 in /usr/local/lib/python3.10/dist-packages (from apache-beam->object-detection==0.1) (3.20.3)\n",
            "Requirement already satisfied: pydot<2,>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from apache-beam->object-detection==0.1) (1.4.2)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.24.0 in /usr/local/lib/python3.10/dist-packages (from apache-beam->object-detection==0.1) (2.31.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.0 in /usr/local/lib/python3.10/dist-packages (from apache-beam->object-detection==0.1) (4.11.0)\n",
            "Collecting zstandard<1,>=0.18.0 (from apache-beam->object-detection==0.1)\n",
            "  Downloading zstandard-0.22.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (5.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.4/5.4 MB\u001b[0m \u001b[31m66.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pyarrow<15.0.0,>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from apache-beam->object-detection==0.1) (14.0.2)\n",
            "Requirement already satisfied: pyarrow-hotfix<1 in /usr/local/lib/python3.10/dist-packages (from apache-beam->object-detection==0.1) (0.6)\n",
            "Requirement already satisfied: cycler>=0.10.0 in /usr/local/lib/python3.10/dist-packages (from lvis->object-detection==0.1) (0.12.1)\n",
            "Requirement already satisfied: kiwisolver>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from lvis->object-detection==0.1) (1.4.5)\n",
            "Requirement already satisfied: opencv-python>=4.1.0.25 in /usr/local/lib/python3.10/dist-packages (from lvis->object-detection==0.1) (4.8.0.76)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->object-detection==0.1) (1.2.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->object-detection==0.1) (4.51.0)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem==0.36.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow_io->object-detection==0.1) (0.36.0)\n",
            "Requirement already satisfied: google-auth<3.0.0dev,>=1.19.0 in /usr/local/lib/python3.10/dist-packages (from google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (2.27.0)\n",
            "Requirement already satisfied: google-auth-httplib2>=0.1.0 in /usr/local/lib/python3.10/dist-packages (from google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (0.1.1)\n",
            "Requirement already satisfied: google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0dev,>=1.31.5 in /usr/local/lib/python3.10/dist-packages (from google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (2.11.1)\n",
            "Requirement already satisfied: uritemplate<5,>=3.0.1 in /usr/local/lib/python3.10/dist-packages (from google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (4.1.1)\n",
            "Collecting docopt (from hdfs<3.0.0,>=2.1.0->apache-beam->object-detection==0.1)\n",
            "  Downloading docopt-0.6.2.tar.gz (25 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: tzlocal>=1.2 in /usr/local/lib/python3.10/dist-packages (from js2py<1,>=0.74->apache-beam->object-detection==0.1) (5.2)\n",
            "Collecting pyjsparser>=2.5.1 (from js2py<1,>=0.74->apache-beam->object-detection==0.1)\n",
            "  Downloading pyjsparser-2.7.1.tar.gz (24 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.10/dist-packages (from jsonschema<5.0.0,>=4.0.0->apache-beam->object-detection==0.1) (23.2.0)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.10/dist-packages (from jsonschema<5.0.0,>=4.0.0->apache-beam->object-detection==0.1) (2023.12.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.10/dist-packages (from jsonschema<5.0.0,>=4.0.0->apache-beam->object-detection==0.1) (0.34.0)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.10/dist-packages (from jsonschema<5.0.0,>=4.0.0->apache-beam->object-detection==0.1) (0.18.0)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from kaggle>=1.3.9->tf-models-official>=2.5.1->object-detection==0.1) (2024.2.2)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from kaggle>=1.3.9->tf-models-official>=2.5.1->object-detection==0.1) (4.66.2)\n",
            "Requirement already satisfied: python-slugify in /usr/local/lib/python3.10/dist-packages (from kaggle>=1.3.9->tf-models-official>=2.5.1->object-detection==0.1) (8.0.4)\n",
            "Requirement already satisfied: urllib3 in /usr/local/lib/python3.10/dist-packages (from kaggle>=1.3.9->tf-models-official>=2.5.1->object-detection==0.1) (2.0.7)\n",
            "Requirement already satisfied: bleach in /usr/local/lib/python3.10/dist-packages (from kaggle>=1.3.9->tf-models-official>=2.5.1->object-detection==0.1) (6.1.0)\n",
            "Collecting dnspython<3.0.0,>=1.16.0 (from pymongo<5.0.0,>=3.8.0->apache-beam->object-detection==0.1)\n",
            "  Downloading dnspython-2.6.1-py3-none-any.whl (307 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m307.7/307.7 kB\u001b[0m \u001b[31m32.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.24.0->apache-beam->object-detection==0.1) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.24.0->apache-beam->object-detection==0.1) (3.7)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow~=2.16.1->tf-models-official>=2.5.1->object-detection==0.1) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=23.5.26 in /usr/local/lib/python3.10/dist-packages (from tensorflow~=2.16.1->tf-models-official>=2.5.1->object-detection==0.1) (24.3.25)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow~=2.16.1->tf-models-official>=2.5.1->object-detection==0.1) (0.5.4)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow~=2.16.1->tf-models-official>=2.5.1->object-detection==0.1) (0.2.0)\n",
            "Collecting h5py>=3.10.0 (from tensorflow~=2.16.1->tf-models-official>=2.5.1->object-detection==0.1)\n",
            "  Downloading h5py-3.11.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (5.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.3/5.3 MB\u001b[0m \u001b[31m88.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow~=2.16.1->tf-models-official>=2.5.1->object-detection==0.1) (18.1.1)\n",
            "Collecting ml-dtypes~=0.3.1 (from tensorflow~=2.16.1->tf-models-official>=2.5.1->object-detection==0.1)\n",
            "  Downloading ml_dtypes-0.3.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.2/2.2 MB\u001b[0m \u001b[31m75.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.10/dist-packages (from tensorflow~=2.16.1->tf-models-official>=2.5.1->object-detection==0.1) (3.3.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from tensorflow~=2.16.1->tf-models-official>=2.5.1->object-detection==0.1) (67.7.2)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow~=2.16.1->tf-models-official>=2.5.1->object-detection==0.1) (2.4.0)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow~=2.16.1->tf-models-official>=2.5.1->object-detection==0.1) (1.14.1)\n",
            "Collecting tensorboard<2.17,>=2.16 (from tensorflow~=2.16.1->tf-models-official>=2.5.1->object-detection==0.1)\n",
            "  Downloading tensorboard-2.16.2-py3-none-any.whl (5.5 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.5/5.5 MB\u001b[0m \u001b[31m89.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting keras (from object-detection==0.1)\n",
            "  Downloading keras-3.3.3-py3-none-any.whl (1.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m60.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: rich in /usr/local/lib/python3.10/dist-packages (from keras->object-detection==0.1) (13.7.1)\n",
            "Collecting namex (from keras->object-detection==0.1)\n",
            "  Downloading namex-0.0.8-py3-none-any.whl (5.8 kB)\n",
            "Collecting optree (from keras->object-detection==0.1)\n",
            "  Downloading optree-0.11.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (311 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m311.2/311.2 kB\u001b[0m \u001b[31m33.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: dm-tree~=0.1.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow-model-optimization>=0.4.1->tf-models-official>=2.5.1->object-detection==0.1) (0.1.8)\n",
            "Requirement already satisfied: pyasn1>=0.1.7 in /usr/local/lib/python3.10/dist-packages (from oauth2client->tf-models-official>=2.5.1->object-detection==0.1) (0.6.0)\n",
            "Requirement already satisfied: pyasn1-modules>=0.0.5 in /usr/local/lib/python3.10/dist-packages (from oauth2client->tf-models-official>=2.5.1->object-detection==0.1) (0.4.0)\n",
            "Requirement already satisfied: rsa>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from oauth2client->tf-models-official>=2.5.1->object-detection==0.1) (4.9)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich->keras->object-detection==0.1) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich->keras->object-detection==0.1) (2.16.1)\n",
            "Requirement already satisfied: scikit-learn>=0.21.3 in /usr/local/lib/python3.10/dist-packages (from seqeval->tf-models-official>=2.5.1->object-detection==0.1) (1.2.2)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from tensorflow-datasets->tf-models-official>=2.5.1->object-detection==0.1) (8.1.7)\n",
            "Requirement already satisfied: etils[enp,epath,etree]>=0.9.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow-datasets->tf-models-official>=2.5.1->object-detection==0.1) (1.7.0)\n",
            "Requirement already satisfied: promise in /usr/local/lib/python3.10/dist-packages (from tensorflow-datasets->tf-models-official>=2.5.1->object-detection==0.1) (2.3)\n",
            "Requirement already satisfied: tensorflow-metadata in /usr/local/lib/python3.10/dist-packages (from tensorflow-datasets->tf-models-official>=2.5.1->object-detection==0.1) (1.14.0)\n",
            "Requirement already satisfied: toml in /usr/local/lib/python3.10/dist-packages (from tensorflow-datasets->tf-models-official>=2.5.1->object-detection==0.1) (0.10.2)\n",
            "Requirement already satisfied: array-record>=0.5.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow-datasets->tf-models-official>=2.5.1->object-detection==0.1) (0.5.1)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from astunparse>=1.6.0->tensorflow~=2.16.1->tf-models-official>=2.5.1->object-detection==0.1) (0.43.0)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from etils[enp,epath,etree]>=0.9.0->tensorflow-datasets->tf-models-official>=2.5.1->object-detection==0.1) (2023.6.0)\n",
            "Requirement already satisfied: importlib_resources in /usr/local/lib/python3.10/dist-packages (from etils[enp,epath,etree]>=0.9.0->tensorflow-datasets->tf-models-official>=2.5.1->object-detection==0.1) (6.4.0)\n",
            "Requirement already satisfied: zipp in /usr/local/lib/python3.10/dist-packages (from etils[enp,epath,etree]>=0.9.0->tensorflow-datasets->tf-models-official>=2.5.1->object-detection==0.1) (3.18.1)\n",
            "Requirement already satisfied: googleapis-common-protos<2.0.dev0,>=1.56.2 in /usr/local/lib/python3.10/dist-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0dev,>=1.31.5->google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (1.63.0)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth<3.0.0dev,>=1.19.0->google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (5.3.3)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich->keras->object-detection==0.1) (0.1.2)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.21.3->seqeval->tf-models-official>=2.5.1->object-detection==0.1) (1.4.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.21.3->seqeval->tf-models-official>=2.5.1->object-detection==0.1) (3.4.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.17,>=2.16->tensorflow~=2.16.1->tf-models-official>=2.5.1->object-detection==0.1) (3.6)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.17,>=2.16->tensorflow~=2.16.1->tf-models-official>=2.5.1->object-detection==0.1) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.17,>=2.16->tensorflow~=2.16.1->tf-models-official>=2.5.1->object-detection==0.1) (3.0.2)\n",
            "Requirement already satisfied: webencodings in /usr/local/lib/python3.10/dist-packages (from bleach->kaggle>=1.3.9->tf-models-official>=2.5.1->object-detection==0.1) (0.5.1)\n",
            "Requirement already satisfied: text-unidecode>=1.3 in /usr/local/lib/python3.10/dist-packages (from python-slugify->kaggle>=1.3.9->tf-models-official>=2.5.1->object-detection==0.1) (1.3)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard<2.17,>=2.16->tensorflow~=2.16.1->tf-models-official>=2.5.1->object-detection==0.1) (2.1.5)\n",
            "Building wheels for collected packages: object-detection, avro-python3, crcmod, dill, hdfs, seqeval, pyjsparser, docopt\n",
            "  Building wheel for object-detection (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for object-detection: filename=object_detection-0.1-py3-none-any.whl size=1697356 sha256=fc186aadd62454230238b9deb8b428d92e41219ad8fe62984beb084e9dd09d2b\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-jgva3e1u/wheels/53/dd/70/2de274d6c443c69d367bd6a5606f95e5a6df61aacf1435ec0d\n",
            "  Building wheel for avro-python3 (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for avro-python3: filename=avro_python3-1.10.2-py3-none-any.whl size=43992 sha256=195856a7bfeb4e3a14d1a2cc810fbac503d0a36d005de86a5a4a80be33b505be\n",
            "  Stored in directory: /root/.cache/pip/wheels/bc/85/62/6cdd81c56f923946b401cecff38055b94c9b766927f7d8ca82\n",
            "  Building wheel for crcmod (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for crcmod: filename=crcmod-1.7-cp310-cp310-linux_x86_64.whl size=31407 sha256=079c5b1349c5cabefd8a656027283a201a559f8e7d714c0ac04f7185b38444a1\n",
            "  Stored in directory: /root/.cache/pip/wheels/85/4c/07/72215c529bd59d67e3dac29711d7aba1b692f543c808ba9e86\n",
            "  Building wheel for dill (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for dill: filename=dill-0.3.1.1-py3-none-any.whl size=78541 sha256=89c4e48d89bef0d1ee45b45d7024442e4b48edb22a54c2afed8eab36c2009c98\n",
            "  Stored in directory: /root/.cache/pip/wheels/ea/e2/86/64980d90e297e7bf2ce588c2b96e818f5399c515c4bb8a7e4f\n",
            "  Building wheel for hdfs (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for hdfs: filename=hdfs-2.7.3-py3-none-any.whl size=34324 sha256=ef0e1bd9f0a2985bc733912600336953178b232f62a5835cfcf021c9bab0d44d\n",
            "  Stored in directory: /root/.cache/pip/wheels/e5/8d/b6/99c1c0a3ac5788c866b0ecd3f48b0134a5910e6ed26011800b\n",
            "  Building wheel for seqeval (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for seqeval: filename=seqeval-1.2.2-py3-none-any.whl size=16161 sha256=f4eb5e1c57e2f59a8d0a5391d038c7b0cede966b93f77497a7949bce7b6c58a5\n",
            "  Stored in directory: /root/.cache/pip/wheels/1a/67/4a/ad4082dd7dfc30f2abfe4d80a2ed5926a506eb8a972b4767fa\n",
            "  Building wheel for pyjsparser (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyjsparser: filename=pyjsparser-2.7.1-py3-none-any.whl size=25984 sha256=8bef7f95aead6477fcf3898731134cf3df3f8bc2eab54bb99cf3a5298974aff5\n",
            "  Stored in directory: /root/.cache/pip/wheels/5e/81/26/5956478df303e2bf5a85a5df595bb307bd25948a4bab69f7c7\n",
            "  Building wheel for docopt (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for docopt: filename=docopt-0.6.2-py2.py3-none-any.whl size=13706 sha256=3785cb39479fb1e8b03fef7565a3d920ff4f78e83195d129b66856df8ced15ff\n",
            "  Stored in directory: /root/.cache/pip/wheels/fc/ab/d4/5da2067ac95b36618c629a5f93f809425700506f72c9732fac\n",
            "Successfully built object-detection avro-python3 crcmod dill hdfs seqeval pyjsparser docopt\n",
            "Installing collected packages: pyjsparser, namex, docopt, crcmod, zstandard, tensorflow-model-optimization, tensorflow_io, pyparsing, portalocker, orjson, optree, objsize, ml-dtypes, js2py, immutabledict, h5py, fasteners, fastavro, dnspython, dill, colorama, avro-python3, tensorboard, sacrebleu, pymongo, hdfs, seqeval, lvis, keras, tensorflow, apache-beam, tf-keras, tensorflow-text, tf-models-official, object-detection\n",
            "  Attempting uninstall: pyparsing\n",
            "    Found existing installation: pyparsing 3.1.2\n",
            "    Uninstalling pyparsing-3.1.2:\n",
            "      Successfully uninstalled pyparsing-3.1.2\n",
            "  Attempting uninstall: ml-dtypes\n",
            "    Found existing installation: ml-dtypes 0.2.0\n",
            "    Uninstalling ml-dtypes-0.2.0:\n",
            "      Successfully uninstalled ml-dtypes-0.2.0\n",
            "  Attempting uninstall: h5py\n",
            "    Found existing installation: h5py 3.9.0\n",
            "    Uninstalling h5py-3.9.0:\n",
            "      Successfully uninstalled h5py-3.9.0\n",
            "  Attempting uninstall: tensorboard\n",
            "    Found existing installation: tensorboard 2.15.2\n",
            "    Uninstalling tensorboard-2.15.2:\n",
            "      Successfully uninstalled tensorboard-2.15.2\n",
            "  Attempting uninstall: keras\n",
            "    Found existing installation: keras 2.15.0\n",
            "    Uninstalling keras-2.15.0:\n",
            "      Successfully uninstalled keras-2.15.0\n",
            "  Attempting uninstall: tensorflow\n",
            "    Found existing installation: tensorflow 2.15.0\n",
            "    Uninstalling tensorflow-2.15.0:\n",
            "      Successfully uninstalled tensorflow-2.15.0\n",
            "  Attempting uninstall: tf-keras\n",
            "    Found existing installation: tf_keras 2.15.1\n",
            "    Uninstalling tf_keras-2.15.1:\n",
            "      Successfully uninstalled tf_keras-2.15.1\n",
            "Successfully installed apache-beam-2.55.1 avro-python3-1.10.2 colorama-0.4.6 crcmod-1.7 dill-0.3.1.1 dnspython-2.6.1 docopt-0.6.2 fastavro-1.9.4 fasteners-0.19 h5py-3.11.0 hdfs-2.7.3 immutabledict-4.2.0 js2py-0.74 keras-3.3.3 lvis-0.5.3 ml-dtypes-0.3.2 namex-0.0.8 object-detection-0.1 objsize-0.7.0 optree-0.11.0 orjson-3.10.1 portalocker-2.8.2 pyjsparser-2.7.1 pymongo-4.7.0 pyparsing-2.4.7 sacrebleu-2.2.0 seqeval-1.2.2 tensorboard-2.16.2 tensorflow-2.16.1 tensorflow-model-optimization-0.8.0 tensorflow-text-2.16.1 tensorflow_io-0.36.0 tf-keras-2.16.0 tf-models-official-2.16.0 zstandard-0.22.0\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/tensorflow/models.git\n",
        "%cd models/research\n",
        "!protoc object_detection/protos/*.proto --python_out=.\n",
        "!cp object_detection/packages/tf2/setup.py .\n",
        "!python -m pip install .\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/peonia-api/API_6_Semestre_IA.git"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4n49zyau6wlT",
        "outputId": "78162ed5-c376-4ef4-f173-7886c19510d0"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'API_6_Semestre_IA'...\n",
            "remote: Enumerating objects: 748, done.\u001b[K\n",
            "remote: Counting objects: 100% (68/68), done.\u001b[K\n",
            "remote: Compressing objects: 100% (33/33), done.\u001b[K\n",
            "remote: Total 748 (delta 40), reused 50 (delta 35), pack-reused 680\u001b[K\n",
            "Receiving objects: 100% (748/748), 407.11 MiB | 36.42 MiB/s, done.\n",
            "Resolving deltas: 100% (117/117), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!ls"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4vaamqBS76So",
        "outputId": "ebff5432-0fae-4dca-c80d-51ee25cf6c76"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "models\tsample_data\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!cd API_6_Semestre_IA/ && git checkout feature/dataset-porta"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yWOYTZxK8IMp",
        "outputId": "78fba238-3535-4348-9a8a-a22d1d96cc56"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Updating files: 100% (62/62), done.\n",
            "Branch 'feature/dataset-porta' set up to track remote branch 'feature/dataset-porta' from 'origin'.\n",
            "Switched to a new branch 'feature/dataset-porta'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!wget -c http://download.tensorflow.org/models/object_detection/tf2/20200711/ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8.tar.gz"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KRSMUxsy8aqL",
        "outputId": "11c5a71e-bcfb-4c27-e463-62ffaba50276"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2024-04-27 19:17:13--  http://download.tensorflow.org/models/object_detection/tf2/20200711/ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8.tar.gz\n",
            "Resolving download.tensorflow.org (download.tensorflow.org)... 142.251.111.207, 64.233.180.207, 142.251.16.207, ...\n",
            "Connecting to download.tensorflow.org (download.tensorflow.org)|142.251.111.207|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 20515344 (20M) [application/x-tar]\n",
            "Saving to: ‘ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8.tar.gz’\n",
            "\n",
            "ssd_mobilenet_v2_fp 100%[===================>]  19.56M  --.-KB/s    in 0.1s    \n",
            "\n",
            "2024-04-27 19:17:13 (145 MB/s) - ‘ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8.tar.gz’ saved [20515344/20515344]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!tar -xf ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8.tar.gz"
      ],
      "metadata": {
        "id": "2eQ3C8Om_eE6"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir model && mv ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8 ./model"
      ],
      "metadata": {
        "id": "vmOrwfrbAeoj"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!git checkout feature/dataset-porta"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "69bcBmpL7bBQ",
        "outputId": "4888559e-e54c-4f96-e962-484907ce1459"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "error: pathspec 'feature/dataset-porta' did not match any file(s) known to git\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "qtR98zjvDBqb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install tensorflow==2.13.0"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UHmbshzXCM1o",
        "outputId": "4a16856f-1c5f-4e00-9452-21fcdebaa17a"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: tensorflow==2.13.0 in /usr/local/lib/python3.10/dist-packages (2.13.0)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.13.0) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.13.0) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=23.1.21 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.13.0) (24.3.25)\n",
            "Requirement already satisfied: gast<=0.4.0,>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.13.0) (0.4.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.13.0) (0.2.0)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.13.0) (1.62.2)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.13.0) (3.11.0)\n",
            "Requirement already satisfied: keras<2.14,>=2.13.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.13.0) (2.13.1)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.13.0) (18.1.1)\n",
            "Requirement already satisfied: numpy<=1.24.3,>=1.22 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.13.0) (1.24.3)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.13.0) (3.3.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.13.0) (24.0)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.13.0) (3.20.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.13.0) (67.7.2)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.13.0) (1.16.0)\n",
            "Requirement already satisfied: tensorboard<2.14,>=2.13 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.13.0) (2.13.0)\n",
            "Requirement already satisfied: tensorflow-estimator<2.14,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.13.0) (2.13.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.13.0) (2.4.0)\n",
            "Requirement already satisfied: typing-extensions<4.6.0,>=3.6.6 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.13.0) (4.5.0)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.13.0) (1.14.1)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.13.0) (0.36.0)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from astunparse>=1.6.0->tensorflow==2.13.0) (0.43.0)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.14,>=2.13->tensorflow==2.13.0) (2.27.0)\n",
            "Requirement already satisfied: google-auth-oauthlib<1.1,>=0.5 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.14,>=2.13->tensorflow==2.13.0) (1.0.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.14,>=2.13->tensorflow==2.13.0) (3.6)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.14,>=2.13->tensorflow==2.13.0) (2.31.0)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.14,>=2.13->tensorflow==2.13.0) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.14,>=2.13->tensorflow==2.13.0) (3.0.2)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.14,>=2.13->tensorflow==2.13.0) (5.3.3)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.14,>=2.13->tensorflow==2.13.0) (0.4.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.14,>=2.13->tensorflow==2.13.0) (4.9)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from google-auth-oauthlib<1.1,>=0.5->tensorboard<2.14,>=2.13->tensorflow==2.13.0) (1.3.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.14,>=2.13->tensorflow==2.13.0) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.14,>=2.13->tensorflow==2.13.0) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.14,>=2.13->tensorflow==2.13.0) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.14,>=2.13->tensorflow==2.13.0) (2024.2.2)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard<2.14,>=2.13->tensorflow==2.13.0) (2.1.5)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.14,>=2.13->tensorflow==2.13.0) (0.6.0)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<1.1,>=0.5->tensorboard<2.14,>=2.13->tensorflow==2.13.0) (3.2.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd models/research"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1f43tkkGDEuW",
        "outputId": "7a76dbea-055a-42b7-f82d-d3cb87743a62"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/models/research\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python /content/models/research/object_detection/builders/model_builder_tf2_test.py"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aZvaTv3ZMhdb",
        "outputId": "bcc88e54-378e-4a0c-ba55-7e83a2146296"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2024-04-27 20:14:45.471288: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
            "2024-04-27 20:14:45.526544: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
            "2024-04-27 20:14:45.527257: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2024-04-27 20:14:46.775521: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "Running tests under Python 3.10.12: /usr/bin/python3\n",
            "[ RUN      ] ModelBuilderTF2Test.test_create_center_net_deepmac\n",
            "WARNING:tensorflow:`tf.keras.layers.experimental.SyncBatchNormalization` endpoint is deprecated and will be removed in a future release. Please use `tf.keras.layers.BatchNormalization` with parameter `synchronized` set to True.\n",
            "W0427 20:14:51.155156 133435404271616 batch_normalization.py:1531] `tf.keras.layers.experimental.SyncBatchNormalization` endpoint is deprecated and will be removed in a future release. Please use `tf.keras.layers.BatchNormalization` with parameter `synchronized` set to True.\n",
            "W0427 20:14:51.497628 133435404271616 model_builder.py:1112] Building experimental DeepMAC meta-arch. Some features may be omitted.\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_center_net_deepmac): 0.78s\n",
            "I0427 20:14:51.893770 133435404271616 test_util.py:2462] time(__main__.ModelBuilderTF2Test.test_create_center_net_deepmac): 0.78s\n",
            "[       OK ] ModelBuilderTF2Test.test_create_center_net_deepmac\n",
            "[ RUN      ] ModelBuilderTF2Test.test_create_center_net_model0 (customize_head_params=True)\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_center_net_model0 (customize_head_params=True)): 0.79s\n",
            "I0427 20:14:52.689625 133435404271616 test_util.py:2462] time(__main__.ModelBuilderTF2Test.test_create_center_net_model0 (customize_head_params=True)): 0.79s\n",
            "[       OK ] ModelBuilderTF2Test.test_create_center_net_model0 (customize_head_params=True)\n",
            "[ RUN      ] ModelBuilderTF2Test.test_create_center_net_model1 (customize_head_params=False)\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_center_net_model1 (customize_head_params=False)): 0.73s\n",
            "I0427 20:14:53.423003 133435404271616 test_util.py:2462] time(__main__.ModelBuilderTF2Test.test_create_center_net_model1 (customize_head_params=False)): 0.73s\n",
            "[       OK ] ModelBuilderTF2Test.test_create_center_net_model1 (customize_head_params=False)\n",
            "[ RUN      ] ModelBuilderTF2Test.test_create_center_net_model_from_keypoints\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_center_net_model_from_keypoints): 0.36s\n",
            "I0427 20:14:53.785910 133435404271616 test_util.py:2462] time(__main__.ModelBuilderTF2Test.test_create_center_net_model_from_keypoints): 0.36s\n",
            "[       OK ] ModelBuilderTF2Test.test_create_center_net_model_from_keypoints\n",
            "[ RUN      ] ModelBuilderTF2Test.test_create_center_net_model_mobilenet\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_center_net_model_mobilenet): 2.96s\n",
            "I0427 20:14:56.743280 133435404271616 test_util.py:2462] time(__main__.ModelBuilderTF2Test.test_create_center_net_model_mobilenet): 2.96s\n",
            "[       OK ] ModelBuilderTF2Test.test_create_center_net_model_mobilenet\n",
            "[ RUN      ] ModelBuilderTF2Test.test_create_experimental_model\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_experimental_model): 0.0s\n",
            "I0427 20:14:56.752185 133435404271616 test_util.py:2462] time(__main__.ModelBuilderTF2Test.test_create_experimental_model): 0.0s\n",
            "[       OK ] ModelBuilderTF2Test.test_create_experimental_model\n",
            "[ RUN      ] ModelBuilderTF2Test.test_create_faster_rcnn_from_config_with_crop_feature0 (True)\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_from_config_with_crop_feature0 (True)): 0.04s\n",
            "I0427 20:14:56.795656 133435404271616 test_util.py:2462] time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_from_config_with_crop_feature0 (True)): 0.04s\n",
            "[       OK ] ModelBuilderTF2Test.test_create_faster_rcnn_from_config_with_crop_feature0 (True)\n",
            "[ RUN      ] ModelBuilderTF2Test.test_create_faster_rcnn_from_config_with_crop_feature1 (False)\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_from_config_with_crop_feature1 (False)): 0.03s\n",
            "I0427 20:14:56.822114 133435404271616 test_util.py:2462] time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_from_config_with_crop_feature1 (False)): 0.03s\n",
            "[       OK ] ModelBuilderTF2Test.test_create_faster_rcnn_from_config_with_crop_feature1 (False)\n",
            "[ RUN      ] ModelBuilderTF2Test.test_create_faster_rcnn_model_from_config_with_example_miner\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_model_from_config_with_example_miner): 0.03s\n",
            "I0427 20:14:56.851877 133435404271616 test_util.py:2462] time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_model_from_config_with_example_miner): 0.03s\n",
            "[       OK ] ModelBuilderTF2Test.test_create_faster_rcnn_model_from_config_with_example_miner\n",
            "[ RUN      ] ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_faster_rcnn_with_matmul\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_faster_rcnn_with_matmul): 0.16s\n",
            "I0427 20:14:57.010222 133435404271616 test_util.py:2462] time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_faster_rcnn_with_matmul): 0.16s\n",
            "[       OK ] ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_faster_rcnn_with_matmul\n",
            "[ RUN      ] ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_faster_rcnn_without_matmul\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_faster_rcnn_without_matmul): 0.16s\n",
            "I0427 20:14:57.175555 133435404271616 test_util.py:2462] time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_faster_rcnn_without_matmul): 0.16s\n",
            "[       OK ] ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_faster_rcnn_without_matmul\n",
            "[ RUN      ] ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_mask_rcnn_with_matmul\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_mask_rcnn_with_matmul): 0.15s\n",
            "I0427 20:14:57.329320 133435404271616 test_util.py:2462] time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_mask_rcnn_with_matmul): 0.15s\n",
            "[       OK ] ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_mask_rcnn_with_matmul\n",
            "[ RUN      ] ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_mask_rcnn_without_matmul\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_mask_rcnn_without_matmul): 0.16s\n",
            "I0427 20:14:57.488444 133435404271616 test_util.py:2462] time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_mask_rcnn_without_matmul): 0.16s\n",
            "[       OK ] ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_mask_rcnn_without_matmul\n",
            "[ RUN      ] ModelBuilderTF2Test.test_create_rfcn_model_from_config\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_rfcn_model_from_config): 0.14s\n",
            "I0427 20:14:57.631393 133435404271616 test_util.py:2462] time(__main__.ModelBuilderTF2Test.test_create_rfcn_model_from_config): 0.14s\n",
            "[       OK ] ModelBuilderTF2Test.test_create_rfcn_model_from_config\n",
            "[ RUN      ] ModelBuilderTF2Test.test_create_ssd_fpn_model_from_config\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_ssd_fpn_model_from_config): 0.04s\n",
            "I0427 20:14:57.677140 133435404271616 test_util.py:2462] time(__main__.ModelBuilderTF2Test.test_create_ssd_fpn_model_from_config): 0.04s\n",
            "[       OK ] ModelBuilderTF2Test.test_create_ssd_fpn_model_from_config\n",
            "[ RUN      ] ModelBuilderTF2Test.test_create_ssd_models_from_config\n",
            "I0427 20:14:57.954771 133435404271616 ssd_efficientnet_bifpn_feature_extractor.py:161] EfficientDet EfficientNet backbone version: efficientnet-b0\n",
            "I0427 20:14:57.955017 133435404271616 ssd_efficientnet_bifpn_feature_extractor.py:163] EfficientDet BiFPN num filters: 64\n",
            "I0427 20:14:57.955129 133435404271616 ssd_efficientnet_bifpn_feature_extractor.py:164] EfficientDet BiFPN num iterations: 3\n",
            "I0427 20:14:57.971171 133435404271616 efficientnet_model.py:143] round_filter input=32 output=32\n",
            "I0427 20:14:58.019039 133435404271616 efficientnet_model.py:143] round_filter input=32 output=32\n",
            "I0427 20:14:58.019338 133435404271616 efficientnet_model.py:143] round_filter input=16 output=16\n",
            "I0427 20:14:58.146997 133435404271616 efficientnet_model.py:143] round_filter input=16 output=16\n",
            "I0427 20:14:58.147269 133435404271616 efficientnet_model.py:143] round_filter input=24 output=24\n",
            "I0427 20:14:58.435765 133435404271616 efficientnet_model.py:143] round_filter input=24 output=24\n",
            "I0427 20:14:58.436017 133435404271616 efficientnet_model.py:143] round_filter input=40 output=40\n",
            "I0427 20:14:58.674130 133435404271616 efficientnet_model.py:143] round_filter input=40 output=40\n",
            "I0427 20:14:58.674323 133435404271616 efficientnet_model.py:143] round_filter input=80 output=80\n",
            "I0427 20:14:59.043095 133435404271616 efficientnet_model.py:143] round_filter input=80 output=80\n",
            "I0427 20:14:59.043288 133435404271616 efficientnet_model.py:143] round_filter input=112 output=112\n",
            "I0427 20:14:59.419887 133435404271616 efficientnet_model.py:143] round_filter input=112 output=112\n",
            "I0427 20:14:59.420097 133435404271616 efficientnet_model.py:143] round_filter input=192 output=192\n",
            "I0427 20:15:00.073257 133435404271616 efficientnet_model.py:143] round_filter input=192 output=192\n",
            "I0427 20:15:00.073511 133435404271616 efficientnet_model.py:143] round_filter input=320 output=320\n",
            "I0427 20:15:00.382585 133435404271616 efficientnet_model.py:143] round_filter input=1280 output=1280\n",
            "I0427 20:15:00.536702 133435404271616 efficientnet_model.py:453] Building model efficientnet with params ModelConfig(width_coefficient=1.0, depth_coefficient=1.0, resolution=224, dropout_rate=0.2, blocks=(BlockConfig(input_filters=32, output_filters=16, kernel_size=3, num_repeat=1, expand_ratio=1, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=16, output_filters=24, kernel_size=3, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=24, output_filters=40, kernel_size=5, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=40, output_filters=80, kernel_size=3, num_repeat=3, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=80, output_filters=112, kernel_size=5, num_repeat=3, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=112, output_filters=192, kernel_size=5, num_repeat=4, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=192, output_filters=320, kernel_size=3, num_repeat=1, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise')), stem_base_filters=32, top_base_filters=1280, activation='simple_swish', batch_norm='default', bn_momentum=0.99, bn_epsilon=0.001, weight_decay=5e-06, drop_connect_rate=0.2, depth_divisor=8, min_depth=None, use_se=True, input_channels=3, num_classes=1000, model_name='efficientnet', rescale_input=False, data_format='channels_last', dtype='float32')\n",
            "I0427 20:15:01.100704 133435404271616 ssd_efficientnet_bifpn_feature_extractor.py:161] EfficientDet EfficientNet backbone version: efficientnet-b1\n",
            "I0427 20:15:01.101164 133435404271616 ssd_efficientnet_bifpn_feature_extractor.py:163] EfficientDet BiFPN num filters: 88\n",
            "I0427 20:15:01.101381 133435404271616 ssd_efficientnet_bifpn_feature_extractor.py:164] EfficientDet BiFPN num iterations: 4\n",
            "I0427 20:15:01.108493 133435404271616 efficientnet_model.py:143] round_filter input=32 output=32\n",
            "I0427 20:15:01.178608 133435404271616 efficientnet_model.py:143] round_filter input=32 output=32\n",
            "I0427 20:15:01.178928 133435404271616 efficientnet_model.py:143] round_filter input=16 output=16\n",
            "I0427 20:15:01.502936 133435404271616 efficientnet_model.py:143] round_filter input=16 output=16\n",
            "I0427 20:15:01.503283 133435404271616 efficientnet_model.py:143] round_filter input=24 output=24\n",
            "I0427 20:15:02.018371 133435404271616 efficientnet_model.py:143] round_filter input=24 output=24\n",
            "I0427 20:15:02.018650 133435404271616 efficientnet_model.py:143] round_filter input=40 output=40\n",
            "I0427 20:15:02.525504 133435404271616 efficientnet_model.py:143] round_filter input=40 output=40\n",
            "I0427 20:15:02.525805 133435404271616 efficientnet_model.py:143] round_filter input=80 output=80\n",
            "I0427 20:15:03.327677 133435404271616 efficientnet_model.py:143] round_filter input=80 output=80\n",
            "I0427 20:15:03.327992 133435404271616 efficientnet_model.py:143] round_filter input=112 output=112\n",
            "I0427 20:15:03.943111 133435404271616 efficientnet_model.py:143] round_filter input=112 output=112\n",
            "I0427 20:15:03.943351 133435404271616 efficientnet_model.py:143] round_filter input=192 output=192\n",
            "I0427 20:15:04.590579 133435404271616 efficientnet_model.py:143] round_filter input=192 output=192\n",
            "I0427 20:15:04.590852 133435404271616 efficientnet_model.py:143] round_filter input=320 output=320\n",
            "I0427 20:15:04.937526 133435404271616 efficientnet_model.py:143] round_filter input=1280 output=1280\n",
            "I0427 20:15:05.013366 133435404271616 efficientnet_model.py:453] Building model efficientnet with params ModelConfig(width_coefficient=1.0, depth_coefficient=1.1, resolution=240, dropout_rate=0.2, blocks=(BlockConfig(input_filters=32, output_filters=16, kernel_size=3, num_repeat=1, expand_ratio=1, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=16, output_filters=24, kernel_size=3, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=24, output_filters=40, kernel_size=5, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=40, output_filters=80, kernel_size=3, num_repeat=3, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=80, output_filters=112, kernel_size=5, num_repeat=3, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=112, output_filters=192, kernel_size=5, num_repeat=4, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=192, output_filters=320, kernel_size=3, num_repeat=1, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise')), stem_base_filters=32, top_base_filters=1280, activation='simple_swish', batch_norm='default', bn_momentum=0.99, bn_epsilon=0.001, weight_decay=5e-06, drop_connect_rate=0.2, depth_divisor=8, min_depth=None, use_se=True, input_channels=3, num_classes=1000, model_name='efficientnet', rescale_input=False, data_format='channels_last', dtype='float32')\n",
            "I0427 20:15:05.100168 133435404271616 ssd_efficientnet_bifpn_feature_extractor.py:161] EfficientDet EfficientNet backbone version: efficientnet-b2\n",
            "I0427 20:15:05.100408 133435404271616 ssd_efficientnet_bifpn_feature_extractor.py:163] EfficientDet BiFPN num filters: 112\n",
            "I0427 20:15:05.100498 133435404271616 ssd_efficientnet_bifpn_feature_extractor.py:164] EfficientDet BiFPN num iterations: 5\n",
            "I0427 20:15:05.103031 133435404271616 efficientnet_model.py:143] round_filter input=32 output=32\n",
            "I0427 20:15:05.126860 133435404271616 efficientnet_model.py:143] round_filter input=32 output=32\n",
            "I0427 20:15:05.127119 133435404271616 efficientnet_model.py:143] round_filter input=16 output=16\n",
            "I0427 20:15:05.331489 133435404271616 efficientnet_model.py:143] round_filter input=16 output=16\n",
            "I0427 20:15:05.331751 133435404271616 efficientnet_model.py:143] round_filter input=24 output=24\n",
            "I0427 20:15:05.731300 133435404271616 efficientnet_model.py:143] round_filter input=24 output=24\n",
            "I0427 20:15:05.731552 133435404271616 efficientnet_model.py:143] round_filter input=40 output=48\n",
            "I0427 20:15:06.143017 133435404271616 efficientnet_model.py:143] round_filter input=40 output=48\n",
            "I0427 20:15:06.143288 133435404271616 efficientnet_model.py:143] round_filter input=80 output=88\n",
            "I0427 20:15:06.691625 133435404271616 efficientnet_model.py:143] round_filter input=80 output=88\n",
            "I0427 20:15:06.691882 133435404271616 efficientnet_model.py:143] round_filter input=112 output=120\n",
            "I0427 20:15:07.243116 133435404271616 efficientnet_model.py:143] round_filter input=112 output=120\n",
            "I0427 20:15:07.243364 133435404271616 efficientnet_model.py:143] round_filter input=192 output=208\n",
            "I0427 20:15:07.945304 133435404271616 efficientnet_model.py:143] round_filter input=192 output=208\n",
            "I0427 20:15:07.945548 133435404271616 efficientnet_model.py:143] round_filter input=320 output=352\n",
            "I0427 20:15:08.270129 133435404271616 efficientnet_model.py:143] round_filter input=1280 output=1408\n",
            "I0427 20:15:08.346598 133435404271616 efficientnet_model.py:453] Building model efficientnet with params ModelConfig(width_coefficient=1.1, depth_coefficient=1.2, resolution=260, dropout_rate=0.3, blocks=(BlockConfig(input_filters=32, output_filters=16, kernel_size=3, num_repeat=1, expand_ratio=1, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=16, output_filters=24, kernel_size=3, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=24, output_filters=40, kernel_size=5, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=40, output_filters=80, kernel_size=3, num_repeat=3, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=80, output_filters=112, kernel_size=5, num_repeat=3, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=112, output_filters=192, kernel_size=5, num_repeat=4, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=192, output_filters=320, kernel_size=3, num_repeat=1, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise')), stem_base_filters=32, top_base_filters=1280, activation='simple_swish', batch_norm='default', bn_momentum=0.99, bn_epsilon=0.001, weight_decay=5e-06, drop_connect_rate=0.2, depth_divisor=8, min_depth=None, use_se=True, input_channels=3, num_classes=1000, model_name='efficientnet', rescale_input=False, data_format='channels_last', dtype='float32')\n",
            "I0427 20:15:08.427305 133435404271616 ssd_efficientnet_bifpn_feature_extractor.py:161] EfficientDet EfficientNet backbone version: efficientnet-b3\n",
            "I0427 20:15:08.427546 133435404271616 ssd_efficientnet_bifpn_feature_extractor.py:163] EfficientDet BiFPN num filters: 160\n",
            "I0427 20:15:08.427646 133435404271616 ssd_efficientnet_bifpn_feature_extractor.py:164] EfficientDet BiFPN num iterations: 6\n",
            "I0427 20:15:08.431580 133435404271616 efficientnet_model.py:143] round_filter input=32 output=40\n",
            "I0427 20:15:08.459014 133435404271616 efficientnet_model.py:143] round_filter input=32 output=40\n",
            "I0427 20:15:08.459215 133435404271616 efficientnet_model.py:143] round_filter input=16 output=24\n",
            "I0427 20:15:08.659189 133435404271616 efficientnet_model.py:143] round_filter input=16 output=24\n",
            "I0427 20:15:08.659372 133435404271616 efficientnet_model.py:143] round_filter input=24 output=32\n",
            "I0427 20:15:08.998556 133435404271616 efficientnet_model.py:143] round_filter input=24 output=32\n",
            "I0427 20:15:08.998758 133435404271616 efficientnet_model.py:143] round_filter input=40 output=48\n",
            "I0427 20:15:09.339553 133435404271616 efficientnet_model.py:143] round_filter input=40 output=48\n",
            "I0427 20:15:09.339743 133435404271616 efficientnet_model.py:143] round_filter input=80 output=96\n",
            "I0427 20:15:09.945063 133435404271616 efficientnet_model.py:143] round_filter input=80 output=96\n",
            "I0427 20:15:09.945329 133435404271616 efficientnet_model.py:143] round_filter input=112 output=136\n",
            "I0427 20:15:10.655159 133435404271616 efficientnet_model.py:143] round_filter input=112 output=136\n",
            "I0427 20:15:10.655422 133435404271616 efficientnet_model.py:143] round_filter input=192 output=232\n",
            "I0427 20:15:11.446522 133435404271616 efficientnet_model.py:143] round_filter input=192 output=232\n",
            "I0427 20:15:11.446758 133435404271616 efficientnet_model.py:143] round_filter input=320 output=384\n",
            "I0427 20:15:11.802696 133435404271616 efficientnet_model.py:143] round_filter input=1280 output=1536\n",
            "I0427 20:15:11.884514 133435404271616 efficientnet_model.py:453] Building model efficientnet with params ModelConfig(width_coefficient=1.2, depth_coefficient=1.4, resolution=300, dropout_rate=0.3, blocks=(BlockConfig(input_filters=32, output_filters=16, kernel_size=3, num_repeat=1, expand_ratio=1, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=16, output_filters=24, kernel_size=3, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=24, output_filters=40, kernel_size=5, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=40, output_filters=80, kernel_size=3, num_repeat=3, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=80, output_filters=112, kernel_size=5, num_repeat=3, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=112, output_filters=192, kernel_size=5, num_repeat=4, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=192, output_filters=320, kernel_size=3, num_repeat=1, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise')), stem_base_filters=32, top_base_filters=1280, activation='simple_swish', batch_norm='default', bn_momentum=0.99, bn_epsilon=0.001, weight_decay=5e-06, drop_connect_rate=0.2, depth_divisor=8, min_depth=None, use_se=True, input_channels=3, num_classes=1000, model_name='efficientnet', rescale_input=False, data_format='channels_last', dtype='float32')\n",
            "I0427 20:15:11.975883 133435404271616 ssd_efficientnet_bifpn_feature_extractor.py:161] EfficientDet EfficientNet backbone version: efficientnet-b4\n",
            "I0427 20:15:11.976108 133435404271616 ssd_efficientnet_bifpn_feature_extractor.py:163] EfficientDet BiFPN num filters: 224\n",
            "I0427 20:15:11.976201 133435404271616 ssd_efficientnet_bifpn_feature_extractor.py:164] EfficientDet BiFPN num iterations: 7\n",
            "I0427 20:15:11.978626 133435404271616 efficientnet_model.py:143] round_filter input=32 output=48\n",
            "I0427 20:15:12.006692 133435404271616 efficientnet_model.py:143] round_filter input=32 output=48\n",
            "I0427 20:15:12.006879 133435404271616 efficientnet_model.py:143] round_filter input=16 output=24\n",
            "I0427 20:15:12.192477 133435404271616 efficientnet_model.py:143] round_filter input=16 output=24\n",
            "I0427 20:15:12.192670 133435404271616 efficientnet_model.py:143] round_filter input=24 output=32\n",
            "I0427 20:15:12.999686 133435404271616 efficientnet_model.py:143] round_filter input=24 output=32\n",
            "I0427 20:15:12.999885 133435404271616 efficientnet_model.py:143] round_filter input=40 output=56\n",
            "I0427 20:15:13.467379 133435404271616 efficientnet_model.py:143] round_filter input=40 output=56\n",
            "I0427 20:15:13.467575 133435404271616 efficientnet_model.py:143] round_filter input=80 output=112\n",
            "I0427 20:15:14.393836 133435404271616 efficientnet_model.py:143] round_filter input=80 output=112\n",
            "I0427 20:15:14.394092 133435404271616 efficientnet_model.py:143] round_filter input=112 output=160\n",
            "I0427 20:15:15.434318 133435404271616 efficientnet_model.py:143] round_filter input=112 output=160\n",
            "I0427 20:15:15.434558 133435404271616 efficientnet_model.py:143] round_filter input=192 output=272\n",
            "I0427 20:15:16.799927 133435404271616 efficientnet_model.py:143] round_filter input=192 output=272\n",
            "I0427 20:15:16.800140 133435404271616 efficientnet_model.py:143] round_filter input=320 output=448\n",
            "I0427 20:15:17.226227 133435404271616 efficientnet_model.py:143] round_filter input=1280 output=1792\n",
            "I0427 20:15:17.335186 133435404271616 efficientnet_model.py:453] Building model efficientnet with params ModelConfig(width_coefficient=1.4, depth_coefficient=1.8, resolution=380, dropout_rate=0.4, blocks=(BlockConfig(input_filters=32, output_filters=16, kernel_size=3, num_repeat=1, expand_ratio=1, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=16, output_filters=24, kernel_size=3, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=24, output_filters=40, kernel_size=5, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=40, output_filters=80, kernel_size=3, num_repeat=3, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=80, output_filters=112, kernel_size=5, num_repeat=3, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=112, output_filters=192, kernel_size=5, num_repeat=4, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=192, output_filters=320, kernel_size=3, num_repeat=1, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise')), stem_base_filters=32, top_base_filters=1280, activation='simple_swish', batch_norm='default', bn_momentum=0.99, bn_epsilon=0.001, weight_decay=5e-06, drop_connect_rate=0.2, depth_divisor=8, min_depth=None, use_se=True, input_channels=3, num_classes=1000, model_name='efficientnet', rescale_input=False, data_format='channels_last', dtype='float32')\n",
            "I0427 20:15:17.447315 133435404271616 ssd_efficientnet_bifpn_feature_extractor.py:161] EfficientDet EfficientNet backbone version: efficientnet-b5\n",
            "I0427 20:15:17.447565 133435404271616 ssd_efficientnet_bifpn_feature_extractor.py:163] EfficientDet BiFPN num filters: 288\n",
            "I0427 20:15:17.447661 133435404271616 ssd_efficientnet_bifpn_feature_extractor.py:164] EfficientDet BiFPN num iterations: 7\n",
            "I0427 20:15:17.450273 133435404271616 efficientnet_model.py:143] round_filter input=32 output=48\n",
            "I0427 20:15:17.477586 133435404271616 efficientnet_model.py:143] round_filter input=32 output=48\n",
            "I0427 20:15:17.477867 133435404271616 efficientnet_model.py:143] round_filter input=16 output=24\n",
            "I0427 20:15:17.761750 133435404271616 efficientnet_model.py:143] round_filter input=16 output=24\n",
            "I0427 20:15:17.762002 133435404271616 efficientnet_model.py:143] round_filter input=24 output=40\n",
            "I0427 20:15:18.348197 133435404271616 efficientnet_model.py:143] round_filter input=24 output=40\n",
            "I0427 20:15:18.348440 133435404271616 efficientnet_model.py:143] round_filter input=40 output=64\n",
            "I0427 20:15:18.926843 133435404271616 efficientnet_model.py:143] round_filter input=40 output=64\n",
            "I0427 20:15:18.927034 133435404271616 efficientnet_model.py:143] round_filter input=80 output=128\n",
            "I0427 20:15:19.768099 133435404271616 efficientnet_model.py:143] round_filter input=80 output=128\n",
            "I0427 20:15:19.768299 133435404271616 efficientnet_model.py:143] round_filter input=112 output=176\n",
            "I0427 20:15:20.664301 133435404271616 efficientnet_model.py:143] round_filter input=112 output=176\n",
            "I0427 20:15:20.664488 133435404271616 efficientnet_model.py:143] round_filter input=192 output=304\n",
            "I0427 20:15:22.148349 133435404271616 efficientnet_model.py:143] round_filter input=192 output=304\n",
            "I0427 20:15:22.148544 133435404271616 efficientnet_model.py:143] round_filter input=320 output=512\n",
            "I0427 20:15:22.753337 133435404271616 efficientnet_model.py:143] round_filter input=1280 output=2048\n",
            "I0427 20:15:22.850490 133435404271616 efficientnet_model.py:453] Building model efficientnet with params ModelConfig(width_coefficient=1.6, depth_coefficient=2.2, resolution=456, dropout_rate=0.4, blocks=(BlockConfig(input_filters=32, output_filters=16, kernel_size=3, num_repeat=1, expand_ratio=1, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=16, output_filters=24, kernel_size=3, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=24, output_filters=40, kernel_size=5, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=40, output_filters=80, kernel_size=3, num_repeat=3, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=80, output_filters=112, kernel_size=5, num_repeat=3, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=112, output_filters=192, kernel_size=5, num_repeat=4, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=192, output_filters=320, kernel_size=3, num_repeat=1, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise')), stem_base_filters=32, top_base_filters=1280, activation='simple_swish', batch_norm='default', bn_momentum=0.99, bn_epsilon=0.001, weight_decay=5e-06, drop_connect_rate=0.2, depth_divisor=8, min_depth=None, use_se=True, input_channels=3, num_classes=1000, model_name='efficientnet', rescale_input=False, data_format='channels_last', dtype='float32')\n",
            "I0427 20:15:22.977100 133435404271616 ssd_efficientnet_bifpn_feature_extractor.py:161] EfficientDet EfficientNet backbone version: efficientnet-b6\n",
            "I0427 20:15:22.977293 133435404271616 ssd_efficientnet_bifpn_feature_extractor.py:163] EfficientDet BiFPN num filters: 384\n",
            "I0427 20:15:22.977382 133435404271616 ssd_efficientnet_bifpn_feature_extractor.py:164] EfficientDet BiFPN num iterations: 8\n",
            "I0427 20:15:22.979732 133435404271616 efficientnet_model.py:143] round_filter input=32 output=56\n",
            "I0427 20:15:23.014125 133435404271616 efficientnet_model.py:143] round_filter input=32 output=56\n",
            "I0427 20:15:23.015269 133435404271616 efficientnet_model.py:143] round_filter input=16 output=32\n",
            "I0427 20:15:23.279165 133435404271616 efficientnet_model.py:143] round_filter input=16 output=32\n",
            "I0427 20:15:23.279362 133435404271616 efficientnet_model.py:143] round_filter input=24 output=40\n",
            "I0427 20:15:23.921131 133435404271616 efficientnet_model.py:143] round_filter input=24 output=40\n",
            "I0427 20:15:23.921340 133435404271616 efficientnet_model.py:143] round_filter input=40 output=72\n",
            "I0427 20:15:24.660589 133435404271616 efficientnet_model.py:143] round_filter input=40 output=72\n",
            "I0427 20:15:24.660865 133435404271616 efficientnet_model.py:143] round_filter input=80 output=144\n",
            "I0427 20:15:26.073032 133435404271616 efficientnet_model.py:143] round_filter input=80 output=144\n",
            "I0427 20:15:26.073260 133435404271616 efficientnet_model.py:143] round_filter input=112 output=200\n",
            "I0427 20:15:27.623442 133435404271616 efficientnet_model.py:143] round_filter input=112 output=200\n",
            "I0427 20:15:27.625161 133435404271616 efficientnet_model.py:143] round_filter input=192 output=344\n",
            "I0427 20:15:29.819751 133435404271616 efficientnet_model.py:143] round_filter input=192 output=344\n",
            "I0427 20:15:29.820019 133435404271616 efficientnet_model.py:143] round_filter input=320 output=576\n",
            "I0427 20:15:30.526926 133435404271616 efficientnet_model.py:143] round_filter input=1280 output=2304\n",
            "I0427 20:15:30.634689 133435404271616 efficientnet_model.py:453] Building model efficientnet with params ModelConfig(width_coefficient=1.8, depth_coefficient=2.6, resolution=528, dropout_rate=0.5, blocks=(BlockConfig(input_filters=32, output_filters=16, kernel_size=3, num_repeat=1, expand_ratio=1, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=16, output_filters=24, kernel_size=3, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=24, output_filters=40, kernel_size=5, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=40, output_filters=80, kernel_size=3, num_repeat=3, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=80, output_filters=112, kernel_size=5, num_repeat=3, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=112, output_filters=192, kernel_size=5, num_repeat=4, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=192, output_filters=320, kernel_size=3, num_repeat=1, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise')), stem_base_filters=32, top_base_filters=1280, activation='simple_swish', batch_norm='default', bn_momentum=0.99, bn_epsilon=0.001, weight_decay=5e-06, drop_connect_rate=0.2, depth_divisor=8, min_depth=None, use_se=True, input_channels=3, num_classes=1000, model_name='efficientnet', rescale_input=False, data_format='channels_last', dtype='float32')\n",
            "I0427 20:15:30.768616 133435404271616 ssd_efficientnet_bifpn_feature_extractor.py:161] EfficientDet EfficientNet backbone version: efficientnet-b7\n",
            "I0427 20:15:30.768806 133435404271616 ssd_efficientnet_bifpn_feature_extractor.py:163] EfficientDet BiFPN num filters: 384\n",
            "I0427 20:15:30.768887 133435404271616 ssd_efficientnet_bifpn_feature_extractor.py:164] EfficientDet BiFPN num iterations: 8\n",
            "I0427 20:15:30.771541 133435404271616 efficientnet_model.py:143] round_filter input=32 output=64\n",
            "I0427 20:15:30.798115 133435404271616 efficientnet_model.py:143] round_filter input=32 output=64\n",
            "I0427 20:15:30.798296 133435404271616 efficientnet_model.py:143] round_filter input=16 output=32\n",
            "I0427 20:15:31.157485 133435404271616 efficientnet_model.py:143] round_filter input=16 output=32\n",
            "I0427 20:15:31.157679 133435404271616 efficientnet_model.py:143] round_filter input=24 output=48\n",
            "I0427 20:15:31.929737 133435404271616 efficientnet_model.py:143] round_filter input=24 output=48\n",
            "I0427 20:15:31.929935 133435404271616 efficientnet_model.py:143] round_filter input=40 output=80\n",
            "I0427 20:15:32.691329 133435404271616 efficientnet_model.py:143] round_filter input=40 output=80\n",
            "I0427 20:15:32.691526 133435404271616 efficientnet_model.py:143] round_filter input=80 output=160\n",
            "I0427 20:15:33.962990 133435404271616 efficientnet_model.py:143] round_filter input=80 output=160\n",
            "I0427 20:15:33.963269 133435404271616 efficientnet_model.py:143] round_filter input=112 output=224\n",
            "I0427 20:15:35.257710 133435404271616 efficientnet_model.py:143] round_filter input=112 output=224\n",
            "I0427 20:15:35.257947 133435404271616 efficientnet_model.py:143] round_filter input=192 output=384\n",
            "I0427 20:15:37.506894 133435404271616 efficientnet_model.py:143] round_filter input=192 output=384\n",
            "I0427 20:15:37.507103 133435404271616 efficientnet_model.py:143] round_filter input=320 output=640\n",
            "I0427 20:15:38.503039 133435404271616 efficientnet_model.py:143] round_filter input=1280 output=2560\n",
            "I0427 20:15:38.662983 133435404271616 efficientnet_model.py:453] Building model efficientnet with params ModelConfig(width_coefficient=2.0, depth_coefficient=3.1, resolution=600, dropout_rate=0.5, blocks=(BlockConfig(input_filters=32, output_filters=16, kernel_size=3, num_repeat=1, expand_ratio=1, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=16, output_filters=24, kernel_size=3, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=24, output_filters=40, kernel_size=5, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=40, output_filters=80, kernel_size=3, num_repeat=3, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=80, output_filters=112, kernel_size=5, num_repeat=3, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=112, output_filters=192, kernel_size=5, num_repeat=4, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=192, output_filters=320, kernel_size=3, num_repeat=1, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise')), stem_base_filters=32, top_base_filters=1280, activation='simple_swish', batch_norm='default', bn_momentum=0.99, bn_epsilon=0.001, weight_decay=5e-06, drop_connect_rate=0.2, depth_divisor=8, min_depth=None, use_se=True, input_channels=3, num_classes=1000, model_name='efficientnet', rescale_input=False, data_format='channels_last', dtype='float32')\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_ssd_models_from_config): 41.28s\n",
            "I0427 20:15:38.961840 133435404271616 test_util.py:2462] time(__main__.ModelBuilderTF2Test.test_create_ssd_models_from_config): 41.28s\n",
            "[       OK ] ModelBuilderTF2Test.test_create_ssd_models_from_config\n",
            "[ RUN      ] ModelBuilderTF2Test.test_invalid_faster_rcnn_batchnorm_update\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_invalid_faster_rcnn_batchnorm_update): 0.01s\n",
            "I0427 20:15:39.033338 133435404271616 test_util.py:2462] time(__main__.ModelBuilderTF2Test.test_invalid_faster_rcnn_batchnorm_update): 0.01s\n",
            "[       OK ] ModelBuilderTF2Test.test_invalid_faster_rcnn_batchnorm_update\n",
            "[ RUN      ] ModelBuilderTF2Test.test_invalid_first_stage_nms_iou_threshold\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_invalid_first_stage_nms_iou_threshold): 0.0s\n",
            "I0427 20:15:39.036748 133435404271616 test_util.py:2462] time(__main__.ModelBuilderTF2Test.test_invalid_first_stage_nms_iou_threshold): 0.0s\n",
            "[       OK ] ModelBuilderTF2Test.test_invalid_first_stage_nms_iou_threshold\n",
            "[ RUN      ] ModelBuilderTF2Test.test_invalid_model_config_proto\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_invalid_model_config_proto): 0.0s\n",
            "I0427 20:15:39.037806 133435404271616 test_util.py:2462] time(__main__.ModelBuilderTF2Test.test_invalid_model_config_proto): 0.0s\n",
            "[       OK ] ModelBuilderTF2Test.test_invalid_model_config_proto\n",
            "[ RUN      ] ModelBuilderTF2Test.test_invalid_second_stage_batch_size\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_invalid_second_stage_batch_size): 0.0s\n",
            "I0427 20:15:39.041083 133435404271616 test_util.py:2462] time(__main__.ModelBuilderTF2Test.test_invalid_second_stage_batch_size): 0.0s\n",
            "[       OK ] ModelBuilderTF2Test.test_invalid_second_stage_batch_size\n",
            "[ RUN      ] ModelBuilderTF2Test.test_session\n",
            "[  SKIPPED ] ModelBuilderTF2Test.test_session\n",
            "[ RUN      ] ModelBuilderTF2Test.test_unknown_faster_rcnn_feature_extractor\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_unknown_faster_rcnn_feature_extractor): 0.0s\n",
            "I0427 20:15:39.043626 133435404271616 test_util.py:2462] time(__main__.ModelBuilderTF2Test.test_unknown_faster_rcnn_feature_extractor): 0.0s\n",
            "[       OK ] ModelBuilderTF2Test.test_unknown_faster_rcnn_feature_extractor\n",
            "[ RUN      ] ModelBuilderTF2Test.test_unknown_meta_architecture\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_unknown_meta_architecture): 0.0s\n",
            "I0427 20:15:39.044240 133435404271616 test_util.py:2462] time(__main__.ModelBuilderTF2Test.test_unknown_meta_architecture): 0.0s\n",
            "[       OK ] ModelBuilderTF2Test.test_unknown_meta_architecture\n",
            "[ RUN      ] ModelBuilderTF2Test.test_unknown_ssd_feature_extractor\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_unknown_ssd_feature_extractor): 0.0s\n",
            "I0427 20:15:39.045880 133435404271616 test_util.py:2462] time(__main__.ModelBuilderTF2Test.test_unknown_ssd_feature_extractor): 0.0s\n",
            "[       OK ] ModelBuilderTF2Test.test_unknown_ssd_feature_extractor\n",
            "----------------------------------------------------------------------\n",
            "Ran 24 tests in 47.933s\n",
            "\n",
            "OK (skipped=1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python object_detection/model_main_tf2.py --model_dir=./ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8/model.ckpt --pipeline_config_path=./model/ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8/pipeline.config"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ada_O91TBsZ7",
        "outputId": "b15bad8b-a043-498d-cd05-a77e97ee1028"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2024-04-27 21:17:58.655153: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
            "2024-04-27 21:17:59.680317: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
            "2024-04-27 21:17:59.683205: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2024-04-27 21:18:02.706294: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "INFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:CPU:0',)\n",
            "I0427 21:18:11.151674 134053209202688 mirrored_strategy.py:419] Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:CPU:0',)\n",
            "INFO:tensorflow:Maybe overwriting train_steps: None\n",
            "I0427 21:18:11.226216 134053209202688 config_util.py:552] Maybe overwriting train_steps: None\n",
            "INFO:tensorflow:Maybe overwriting use_bfloat16: False\n",
            "I0427 21:18:11.226495 134053209202688 config_util.py:552] Maybe overwriting use_bfloat16: False\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.10/dist-packages/object_detection/model_lib_v2.py:563: StrategyBase.experimental_distribute_datasets_from_function (from tensorflow.python.distribute.distribute_lib) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "rename to distribute_datasets_from_function\n",
            "W0427 21:18:11.264765 134053209202688 deprecation.py:364] From /usr/local/lib/python3.10/dist-packages/object_detection/model_lib_v2.py:563: StrategyBase.experimental_distribute_datasets_from_function (from tensorflow.python.distribute.distribute_lib) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "rename to distribute_datasets_from_function\n",
            "INFO:tensorflow:Reading unweighted datasets: ['./API_6_Semestre_IA/dataset/annotations/train_record']\n",
            "I0427 21:18:11.277718 134053209202688 dataset_builder.py:162] Reading unweighted datasets: ['./API_6_Semestre_IA/dataset/annotations/train_record']\n",
            "INFO:tensorflow:Reading record datasets for input file: ['./API_6_Semestre_IA/dataset/annotations/train_record']\n",
            "I0427 21:18:11.278093 134053209202688 dataset_builder.py:79] Reading record datasets for input file: ['./API_6_Semestre_IA/dataset/annotations/train_record']\n",
            "INFO:tensorflow:Number of filenames to read: 1\n",
            "I0427 21:18:11.278255 134053209202688 dataset_builder.py:80] Number of filenames to read: 1\n",
            "WARNING:tensorflow:num_readers has been reduced to 1 to match input file shards.\n",
            "W0427 21:18:11.278349 134053209202688 dataset_builder.py:86] num_readers has been reduced to 1 to match input file shards.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.10/dist-packages/object_detection/builders/dataset_builder.py:100: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.deterministic`.\n",
            "W0427 21:18:11.299659 134053209202688 deprecation.py:364] From /usr/local/lib/python3.10/dist-packages/object_detection/builders/dataset_builder.py:100: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.deterministic`.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.10/dist-packages/object_detection/builders/dataset_builder.py:235: DatasetV1.map_with_legacy_function (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.data.Dataset.map()\n",
            "W0427 21:18:11.334004 134053209202688 deprecation.py:364] From /usr/local/lib/python3.10/dist-packages/object_detection/builders/dataset_builder.py:235: DatasetV1.map_with_legacy_function (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.data.Dataset.map()\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.10/dist-packages/tensorflow/python/util/dispatch.py:1176: sparse_to_dense (from tensorflow.python.ops.sparse_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Create a `tf.sparse.SparseTensor` and use `tf.sparse.to_dense` instead.\n",
            "W0427 21:18:20.810982 134053209202688 deprecation.py:364] From /usr/local/lib/python3.10/dist-packages/tensorflow/python/util/dispatch.py:1176: sparse_to_dense (from tensorflow.python.ops.sparse_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Create a `tf.sparse.SparseTensor` and use `tf.sparse.to_dense` instead.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.10/dist-packages/tensorflow/python/util/dispatch.py:1176: sample_distorted_bounding_box (from tensorflow.python.ops.image_ops_impl) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "`seed2` arg is deprecated.Use sample_distorted_bounding_box_v2 instead.\n",
            "W0427 21:18:24.047626 134053209202688 deprecation.py:364] From /usr/local/lib/python3.10/dist-packages/tensorflow/python/util/dispatch.py:1176: sample_distorted_bounding_box (from tensorflow.python.ops.image_ops_impl) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "`seed2` arg is deprecated.Use sample_distorted_bounding_box_v2 instead.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.10/dist-packages/tensorflow/python/util/dispatch.py:1176: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.cast` instead.\n",
            "W0427 21:18:26.064267 134053209202688 deprecation.py:364] From /usr/local/lib/python3.10/dist-packages/tensorflow/python/util/dispatch.py:1176: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.cast` instead.\n",
            "2024-04-27 21:18:29.983755: W tensorflow/core/framework/dataset.cc:956] Input of GeneratorDatasetOp::Dataset will not be optimized because the dataset does not implement the AsGraphDefInternal() method needed to apply optimizations.\n",
            "/usr/local/lib/python3.10/dist-packages/keras/src/backend.py:452: UserWarning: `tf.keras.backend.set_learning_phase` is deprecated and will be removed after 2020-10-11. To update it, simply pass a True/False value to the `training` argument of the `__call__` method of your layer or model.\n",
            "  warnings.warn(\n",
            "I0427 21:18:57.132875 134050358490688 api.py:460] feature_map_spatial_dims: [(40, 40), (20, 20), (10, 10), (5, 5), (3, 3)]\n",
            "I0427 21:19:08.121824 134050358490688 api.py:460] feature_map_spatial_dims: [(40, 40), (20, 20), (10, 10), (5, 5), (3, 3)]\n",
            "2024-04-27 21:19:12.956632: W tensorflow/core/framework/dataset.cc:956] Input of GeneratorDatasetOp::Dataset will not be optimized because the dataset does not implement the AsGraphDefInternal() method needed to apply optimizations.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.10/dist-packages/tensorflow/python/util/deprecation.py:648: calling map_fn_v2 (from tensorflow.python.ops.map_fn) with dtype is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use fn_output_signature instead\n",
            "W0427 21:19:14.149927 134050664674880 deprecation.py:569] From /usr/local/lib/python3.10/dist-packages/tensorflow/python/util/deprecation.py:648: calling map_fn_v2 (from tensorflow.python.ops.map_fn) with dtype is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use fn_output_signature instead\n",
            "I0427 21:19:15.192268 134050664674880 api.py:460] feature_map_spatial_dims: [(40, 40), (20, 20), (10, 10), (5, 5), (3, 3)]\n",
            "I0427 21:19:21.965186 134050664674880 api.py:460] feature_map_spatial_dims: [(40, 40), (20, 20), (10, 10), (5, 5), (3, 3)]\n",
            "I0427 21:19:27.136713 134050664674880 api.py:460] feature_map_spatial_dims: [(40, 40), (20, 20), (10, 10), (5, 5), (3, 3)]\n",
            "I0427 21:19:33.167432 134050664674880 api.py:460] feature_map_spatial_dims: [(40, 40), (20, 20), (10, 10), (5, 5), (3, 3)]\n",
            "INFO:tensorflow:Step 100 per-step time 1.989s\n",
            "I0427 21:22:32.616360 134053209202688 model_lib_v2.py:705] Step 100 per-step time 1.989s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.0011233081,\n",
            " 'Loss/localization_loss': 0.73557204,\n",
            " 'Loss/regularization_loss': 0.15312505,\n",
            " 'Loss/total_loss': 0.8898204,\n",
            " 'learning_rate': 0.0319994}\n",
            "I0427 21:22:32.623611 134053209202688 model_lib_v2.py:708] {'Loss/classification_loss': 0.0011233081,\n",
            " 'Loss/localization_loss': 0.73557204,\n",
            " 'Loss/regularization_loss': 0.15312505,\n",
            " 'Loss/total_loss': 0.8898204,\n",
            " 'learning_rate': 0.0319994}\n",
            "INFO:tensorflow:Step 200 per-step time 1.655s\n",
            "I0427 21:25:18.124042 134053209202688 model_lib_v2.py:705] Step 200 per-step time 1.655s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.0012814262,\n",
            " 'Loss/localization_loss': 0.59328204,\n",
            " 'Loss/regularization_loss': 0.15270777,\n",
            " 'Loss/total_loss': 0.74727124,\n",
            " 'learning_rate': 0.0373328}\n",
            "I0427 21:25:18.132682 134053209202688 model_lib_v2.py:708] {'Loss/classification_loss': 0.0012814262,\n",
            " 'Loss/localization_loss': 0.59328204,\n",
            " 'Loss/regularization_loss': 0.15270777,\n",
            " 'Loss/total_loss': 0.74727124,\n",
            " 'learning_rate': 0.0373328}\n",
            "INFO:tensorflow:Step 300 per-step time 1.633s\n",
            "I0427 21:28:01.410841 134053209202688 model_lib_v2.py:705] Step 300 per-step time 1.633s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.00082241587,\n",
            " 'Loss/localization_loss': 0.5878476,\n",
            " 'Loss/regularization_loss': 0.15222664,\n",
            " 'Loss/total_loss': 0.74089664,\n",
            " 'learning_rate': 0.0426662}\n",
            "I0427 21:28:01.418650 134053209202688 model_lib_v2.py:708] {'Loss/classification_loss': 0.00082241587,\n",
            " 'Loss/localization_loss': 0.5878476,\n",
            " 'Loss/regularization_loss': 0.15222664,\n",
            " 'Loss/total_loss': 0.74089664,\n",
            " 'learning_rate': 0.0426662}\n",
            "INFO:tensorflow:Step 400 per-step time 1.682s\n",
            "I0427 21:30:49.655025 134053209202688 model_lib_v2.py:705] Step 400 per-step time 1.682s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.0016482093,\n",
            " 'Loss/localization_loss': 0.66893786,\n",
            " 'Loss/regularization_loss': 0.15168229,\n",
            " 'Loss/total_loss': 0.82226837,\n",
            " 'learning_rate': 0.047999598}\n",
            "I0427 21:30:49.655631 134053209202688 model_lib_v2.py:708] {'Loss/classification_loss': 0.0016482093,\n",
            " 'Loss/localization_loss': 0.66893786,\n",
            " 'Loss/regularization_loss': 0.15168229,\n",
            " 'Loss/total_loss': 0.82226837,\n",
            " 'learning_rate': 0.047999598}\n",
            "INFO:tensorflow:Step 500 per-step time 1.595s\n",
            "I0427 21:33:29.167724 134053209202688 model_lib_v2.py:705] Step 500 per-step time 1.595s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.001047048,\n",
            " 'Loss/localization_loss': 0.40592337,\n",
            " 'Loss/regularization_loss': 0.15107536,\n",
            " 'Loss/total_loss': 0.55804574,\n",
            " 'learning_rate': 0.053333}\n",
            "I0427 21:33:29.168350 134053209202688 model_lib_v2.py:708] {'Loss/classification_loss': 0.001047048,\n",
            " 'Loss/localization_loss': 0.40592337,\n",
            " 'Loss/regularization_loss': 0.15107536,\n",
            " 'Loss/total_loss': 0.55804574,\n",
            " 'learning_rate': 0.053333}\n",
            "INFO:tensorflow:Step 600 per-step time 1.671s\n",
            "I0427 21:36:16.326986 134053209202688 model_lib_v2.py:705] Step 600 per-step time 1.671s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.0023035435,\n",
            " 'Loss/localization_loss': 0.7075495,\n",
            " 'Loss/regularization_loss': 0.15040666,\n",
            " 'Loss/total_loss': 0.8602597,\n",
            " 'learning_rate': 0.0586664}\n",
            "I0427 21:36:16.327644 134053209202688 model_lib_v2.py:708] {'Loss/classification_loss': 0.0023035435,\n",
            " 'Loss/localization_loss': 0.7075495,\n",
            " 'Loss/regularization_loss': 0.15040666,\n",
            " 'Loss/total_loss': 0.8602597,\n",
            " 'learning_rate': 0.0586664}\n",
            "INFO:tensorflow:Step 700 per-step time 1.619s\n",
            "I0427 21:38:58.274916 134053209202688 model_lib_v2.py:705] Step 700 per-step time 1.619s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.0009805938,\n",
            " 'Loss/localization_loss': 0.5637761,\n",
            " 'Loss/regularization_loss': 0.14967702,\n",
            " 'Loss/total_loss': 0.71443367,\n",
            " 'learning_rate': 0.0639998}\n",
            "I0427 21:38:58.282766 134053209202688 model_lib_v2.py:708] {'Loss/classification_loss': 0.0009805938,\n",
            " 'Loss/localization_loss': 0.5637761,\n",
            " 'Loss/regularization_loss': 0.14967702,\n",
            " 'Loss/total_loss': 0.71443367,\n",
            " 'learning_rate': 0.0639998}\n",
            "INFO:tensorflow:Step 800 per-step time 1.569s\n",
            "I0427 21:41:35.137274 134053209202688 model_lib_v2.py:705] Step 800 per-step time 1.569s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.00074890524,\n",
            " 'Loss/localization_loss': 0.4236083,\n",
            " 'Loss/regularization_loss': 0.14888734,\n",
            " 'Loss/total_loss': 0.5732446,\n",
            " 'learning_rate': 0.069333196}\n",
            "I0427 21:41:35.144725 134053209202688 model_lib_v2.py:708] {'Loss/classification_loss': 0.00074890524,\n",
            " 'Loss/localization_loss': 0.4236083,\n",
            " 'Loss/regularization_loss': 0.14888734,\n",
            " 'Loss/total_loss': 0.5732446,\n",
            " 'learning_rate': 0.069333196}\n",
            "INFO:tensorflow:Step 900 per-step time 1.681s\n",
            "I0427 21:44:23.281547 134053209202688 model_lib_v2.py:705] Step 900 per-step time 1.681s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.00091654464,\n",
            " 'Loss/localization_loss': 0.45354638,\n",
            " 'Loss/regularization_loss': 0.1480386,\n",
            " 'Loss/total_loss': 0.6025015,\n",
            " 'learning_rate': 0.074666604}\n",
            "I0427 21:44:23.283578 134053209202688 model_lib_v2.py:708] {'Loss/classification_loss': 0.00091654464,\n",
            " 'Loss/localization_loss': 0.45354638,\n",
            " 'Loss/regularization_loss': 0.1480386,\n",
            " 'Loss/total_loss': 0.6025015,\n",
            " 'learning_rate': 0.074666604}\n",
            "INFO:tensorflow:Step 1000 per-step time 1.573s\n",
            "I0427 21:47:00.561808 134053209202688 model_lib_v2.py:705] Step 1000 per-step time 1.573s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.001151614,\n",
            " 'Loss/localization_loss': 0.40632793,\n",
            " 'Loss/regularization_loss': 0.1471319,\n",
            " 'Loss/total_loss': 0.55461144,\n",
            " 'learning_rate': 0.08}\n",
            "I0427 21:47:00.562458 134053209202688 model_lib_v2.py:708] {'Loss/classification_loss': 0.001151614,\n",
            " 'Loss/localization_loss': 0.40632793,\n",
            " 'Loss/regularization_loss': 0.1471319,\n",
            " 'Loss/total_loss': 0.55461144,\n",
            " 'learning_rate': 0.08}\n",
            "INFO:tensorflow:Step 1100 per-step time 1.734s\n",
            "I0427 21:49:53.987116 134053209202688 model_lib_v2.py:705] Step 1100 per-step time 1.734s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.0008829715,\n",
            " 'Loss/localization_loss': 0.5948909,\n",
            " 'Loss/regularization_loss': 0.14619361,\n",
            " 'Loss/total_loss': 0.74196744,\n",
            " 'learning_rate': 0.07999918}\n",
            "I0427 21:49:53.999622 134053209202688 model_lib_v2.py:708] {'Loss/classification_loss': 0.0008829715,\n",
            " 'Loss/localization_loss': 0.5948909,\n",
            " 'Loss/regularization_loss': 0.14619361,\n",
            " 'Loss/total_loss': 0.74196744,\n",
            " 'learning_rate': 0.07999918}\n",
            "INFO:tensorflow:Step 1200 per-step time 1.591s\n",
            "I0427 21:52:33.133592 134053209202688 model_lib_v2.py:705] Step 1200 per-step time 1.591s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.00077954534,\n",
            " 'Loss/localization_loss': 0.43170142,\n",
            " 'Loss/regularization_loss': 0.1452607,\n",
            " 'Loss/total_loss': 0.5777417,\n",
            " 'learning_rate': 0.079996705}\n",
            "I0427 21:52:33.134350 134053209202688 model_lib_v2.py:708] {'Loss/classification_loss': 0.00077954534,\n",
            " 'Loss/localization_loss': 0.43170142,\n",
            " 'Loss/regularization_loss': 0.1452607,\n",
            " 'Loss/total_loss': 0.5777417,\n",
            " 'learning_rate': 0.079996705}\n",
            "INFO:tensorflow:Step 1300 per-step time 1.620s\n",
            "I0427 21:55:15.167724 134053209202688 model_lib_v2.py:705] Step 1300 per-step time 1.620s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.00062823197,\n",
            " 'Loss/localization_loss': 0.532126,\n",
            " 'Loss/regularization_loss': 0.14433376,\n",
            " 'Loss/total_loss': 0.677088,\n",
            " 'learning_rate': 0.0799926}\n",
            "I0427 21:55:15.174855 134053209202688 model_lib_v2.py:708] {'Loss/classification_loss': 0.00062823197,\n",
            " 'Loss/localization_loss': 0.532126,\n",
            " 'Loss/regularization_loss': 0.14433376,\n",
            " 'Loss/total_loss': 0.677088,\n",
            " 'learning_rate': 0.0799926}\n",
            "INFO:tensorflow:Step 1400 per-step time 1.588s\n",
            "I0427 21:57:54.012513 134053209202688 model_lib_v2.py:705] Step 1400 per-step time 1.588s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.00086096546,\n",
            " 'Loss/localization_loss': 0.46870592,\n",
            " 'Loss/regularization_loss': 0.14341281,\n",
            " 'Loss/total_loss': 0.6129797,\n",
            " 'learning_rate': 0.07998685}\n",
            "I0427 21:57:54.013175 134053209202688 model_lib_v2.py:708] {'Loss/classification_loss': 0.00086096546,\n",
            " 'Loss/localization_loss': 0.46870592,\n",
            " 'Loss/regularization_loss': 0.14341281,\n",
            " 'Loss/total_loss': 0.6129797,\n",
            " 'learning_rate': 0.07998685}\n",
            "INFO:tensorflow:Step 1500 per-step time 1.649s\n",
            "I0427 22:00:38.945632 134053209202688 model_lib_v2.py:705] Step 1500 per-step time 1.649s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.0018911011,\n",
            " 'Loss/localization_loss': 0.5690381,\n",
            " 'Loss/regularization_loss': 0.1424978,\n",
            " 'Loss/total_loss': 0.713427,\n",
            " 'learning_rate': 0.07997945}\n",
            "I0427 22:00:38.952583 134053209202688 model_lib_v2.py:708] {'Loss/classification_loss': 0.0018911011,\n",
            " 'Loss/localization_loss': 0.5690381,\n",
            " 'Loss/regularization_loss': 0.1424978,\n",
            " 'Loss/total_loss': 0.713427,\n",
            " 'learning_rate': 0.07997945}\n",
            "INFO:tensorflow:Step 1600 per-step time 1.672s\n",
            "I0427 22:03:26.123825 134053209202688 model_lib_v2.py:705] Step 1600 per-step time 1.672s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.00085517316,\n",
            " 'Loss/localization_loss': 0.51185685,\n",
            " 'Loss/regularization_loss': 0.14158872,\n",
            " 'Loss/total_loss': 0.65430075,\n",
            " 'learning_rate': 0.079970405}\n",
            "I0427 22:03:26.130602 134053209202688 model_lib_v2.py:708] {'Loss/classification_loss': 0.00085517316,\n",
            " 'Loss/localization_loss': 0.51185685,\n",
            " 'Loss/regularization_loss': 0.14158872,\n",
            " 'Loss/total_loss': 0.65430075,\n",
            " 'learning_rate': 0.079970405}\n",
            "INFO:tensorflow:Step 1700 per-step time 1.616s\n",
            "I0427 22:06:07.681873 134053209202688 model_lib_v2.py:705] Step 1700 per-step time 1.616s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.00043067225,\n",
            " 'Loss/localization_loss': 0.7380368,\n",
            " 'Loss/regularization_loss': 0.14068554,\n",
            " 'Loss/total_loss': 0.879153,\n",
            " 'learning_rate': 0.07995972}\n",
            "I0427 22:06:07.688542 134053209202688 model_lib_v2.py:708] {'Loss/classification_loss': 0.00043067225,\n",
            " 'Loss/localization_loss': 0.7380368,\n",
            " 'Loss/regularization_loss': 0.14068554,\n",
            " 'Loss/total_loss': 0.879153,\n",
            " 'learning_rate': 0.07995972}\n",
            "INFO:tensorflow:Step 1800 per-step time 1.558s\n",
            "I0427 22:08:43.521739 134053209202688 model_lib_v2.py:705] Step 1800 per-step time 1.558s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.00048430669,\n",
            " 'Loss/localization_loss': 0.52908856,\n",
            " 'Loss/regularization_loss': 0.13978826,\n",
            " 'Loss/total_loss': 0.6693611,\n",
            " 'learning_rate': 0.0799474}\n",
            "I0427 22:08:43.522307 134053209202688 model_lib_v2.py:708] {'Loss/classification_loss': 0.00048430669,\n",
            " 'Loss/localization_loss': 0.52908856,\n",
            " 'Loss/regularization_loss': 0.13978826,\n",
            " 'Loss/total_loss': 0.6693611,\n",
            " 'learning_rate': 0.0799474}\n",
            "INFO:tensorflow:Step 1900 per-step time 1.537s\n",
            "I0427 22:11:17.179945 134053209202688 model_lib_v2.py:705] Step 1900 per-step time 1.537s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.00058280997,\n",
            " 'Loss/localization_loss': 0.64961785,\n",
            " 'Loss/regularization_loss': 0.13889684,\n",
            " 'Loss/total_loss': 0.7890975,\n",
            " 'learning_rate': 0.07993342}\n",
            "I0427 22:11:17.187557 134053209202688 model_lib_v2.py:708] {'Loss/classification_loss': 0.00058280997,\n",
            " 'Loss/localization_loss': 0.64961785,\n",
            " 'Loss/regularization_loss': 0.13889684,\n",
            " 'Loss/total_loss': 0.7890975,\n",
            " 'learning_rate': 0.07993342}\n",
            "INFO:tensorflow:Step 2000 per-step time 1.447s\n",
            "I0427 22:13:41.908846 134053209202688 model_lib_v2.py:705] Step 2000 per-step time 1.447s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.0009496752,\n",
            " 'Loss/localization_loss': 0.68772054,\n",
            " 'Loss/regularization_loss': 0.13801128,\n",
            " 'Loss/total_loss': 0.8266815,\n",
            " 'learning_rate': 0.07991781}\n",
            "I0427 22:13:41.909381 134053209202688 model_lib_v2.py:708] {'Loss/classification_loss': 0.0009496752,\n",
            " 'Loss/localization_loss': 0.68772054,\n",
            " 'Loss/regularization_loss': 0.13801128,\n",
            " 'Loss/total_loss': 0.8266815,\n",
            " 'learning_rate': 0.07991781}\n",
            "INFO:tensorflow:Step 2100 per-step time 1.538s\n",
            "I0427 22:16:15.741629 134053209202688 model_lib_v2.py:705] Step 2100 per-step time 1.538s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.0004291512,\n",
            " 'Loss/localization_loss': 0.48278,\n",
            " 'Loss/regularization_loss': 0.13713156,\n",
            " 'Loss/total_loss': 0.6203407,\n",
            " 'learning_rate': 0.07990056}\n",
            "I0427 22:16:15.748523 134053209202688 model_lib_v2.py:708] {'Loss/classification_loss': 0.0004291512,\n",
            " 'Loss/localization_loss': 0.48278,\n",
            " 'Loss/regularization_loss': 0.13713156,\n",
            " 'Loss/total_loss': 0.6203407,\n",
            " 'learning_rate': 0.07990056}\n",
            "INFO:tensorflow:Step 2200 per-step time 1.475s\n",
            "I0427 22:18:43.263857 134053209202688 model_lib_v2.py:705] Step 2200 per-step time 1.475s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.00046461698,\n",
            " 'Loss/localization_loss': 0.44638407,\n",
            " 'Loss/regularization_loss': 0.13625763,\n",
            " 'Loss/total_loss': 0.58310634,\n",
            " 'learning_rate': 0.07988167}\n",
            "I0427 22:18:43.271428 134053209202688 model_lib_v2.py:708] {'Loss/classification_loss': 0.00046461698,\n",
            " 'Loss/localization_loss': 0.44638407,\n",
            " 'Loss/regularization_loss': 0.13625763,\n",
            " 'Loss/total_loss': 0.58310634,\n",
            " 'learning_rate': 0.07988167}\n",
            "INFO:tensorflow:Step 2300 per-step time 1.510s\n",
            "I0427 22:21:14.255480 134053209202688 model_lib_v2.py:705] Step 2300 per-step time 1.510s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.00039482003,\n",
            " 'Loss/localization_loss': 0.57760584,\n",
            " 'Loss/regularization_loss': 0.13538946,\n",
            " 'Loss/total_loss': 0.7133901,\n",
            " 'learning_rate': 0.07986114}\n",
            "I0427 22:21:14.262585 134053209202688 model_lib_v2.py:708] {'Loss/classification_loss': 0.00039482003,\n",
            " 'Loss/localization_loss': 0.57760584,\n",
            " 'Loss/regularization_loss': 0.13538946,\n",
            " 'Loss/total_loss': 0.7133901,\n",
            " 'learning_rate': 0.07986114}\n",
            "INFO:tensorflow:Step 2400 per-step time 1.493s\n",
            "I0427 22:23:43.598302 134053209202688 model_lib_v2.py:705] Step 2400 per-step time 1.493s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.0004301891,\n",
            " 'Loss/localization_loss': 0.52664834,\n",
            " 'Loss/regularization_loss': 0.13452709,\n",
            " 'Loss/total_loss': 0.6616056,\n",
            " 'learning_rate': 0.07983897}\n",
            "I0427 22:23:43.598918 134053209202688 model_lib_v2.py:708] {'Loss/classification_loss': 0.0004301891,\n",
            " 'Loss/localization_loss': 0.52664834,\n",
            " 'Loss/regularization_loss': 0.13452709,\n",
            " 'Loss/total_loss': 0.6616056,\n",
            " 'learning_rate': 0.07983897}\n",
            "INFO:tensorflow:Step 2500 per-step time 1.545s\n",
            "I0427 22:26:18.091005 134053209202688 model_lib_v2.py:705] Step 2500 per-step time 1.545s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.00033443596,\n",
            " 'Loss/localization_loss': 0.43025836,\n",
            " 'Loss/regularization_loss': 0.13367042,\n",
            " 'Loss/total_loss': 0.5642632,\n",
            " 'learning_rate': 0.079815164}\n",
            "I0427 22:26:18.091546 134053209202688 model_lib_v2.py:708] {'Loss/classification_loss': 0.00033443596,\n",
            " 'Loss/localization_loss': 0.43025836,\n",
            " 'Loss/regularization_loss': 0.13367042,\n",
            " 'Loss/total_loss': 0.5642632,\n",
            " 'learning_rate': 0.079815164}\n",
            "INFO:tensorflow:Step 2600 per-step time 1.604s\n",
            "I0427 22:28:58.504997 134053209202688 model_lib_v2.py:705] Step 2600 per-step time 1.604s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.0004157797,\n",
            " 'Loss/localization_loss': 0.69686395,\n",
            " 'Loss/regularization_loss': 0.13281947,\n",
            " 'Loss/total_loss': 0.8300992,\n",
            " 'learning_rate': 0.07978972}\n",
            "I0427 22:28:58.507644 134053209202688 model_lib_v2.py:708] {'Loss/classification_loss': 0.0004157797,\n",
            " 'Loss/localization_loss': 0.69686395,\n",
            " 'Loss/regularization_loss': 0.13281947,\n",
            " 'Loss/total_loss': 0.8300992,\n",
            " 'learning_rate': 0.07978972}\n",
            "INFO:tensorflow:Step 2700 per-step time 1.677s\n",
            "I0427 22:31:46.233431 134053209202688 model_lib_v2.py:705] Step 2700 per-step time 1.677s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.00040993543,\n",
            " 'Loss/localization_loss': 0.5312029,\n",
            " 'Loss/regularization_loss': 0.13197424,\n",
            " 'Loss/total_loss': 0.6635871,\n",
            " 'learning_rate': 0.07976264}\n",
            "I0427 22:31:46.233983 134053209202688 model_lib_v2.py:708] {'Loss/classification_loss': 0.00040993543,\n",
            " 'Loss/localization_loss': 0.5312029,\n",
            " 'Loss/regularization_loss': 0.13197424,\n",
            " 'Loss/total_loss': 0.6635871,\n",
            " 'learning_rate': 0.07976264}\n",
            "INFO:tensorflow:Step 2800 per-step time 1.528s\n",
            "I0427 22:34:19.023192 134053209202688 model_lib_v2.py:705] Step 2800 per-step time 1.528s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.00040032243,\n",
            " 'Loss/localization_loss': 0.47626176,\n",
            " 'Loss/regularization_loss': 0.13113469,\n",
            " 'Loss/total_loss': 0.6077968,\n",
            " 'learning_rate': 0.07973392}\n",
            "I0427 22:34:19.030564 134053209202688 model_lib_v2.py:708] {'Loss/classification_loss': 0.00040032243,\n",
            " 'Loss/localization_loss': 0.47626176,\n",
            " 'Loss/regularization_loss': 0.13113469,\n",
            " 'Loss/total_loss': 0.6077968,\n",
            " 'learning_rate': 0.07973392}\n",
            "INFO:tensorflow:Step 2900 per-step time 1.465s\n",
            "I0427 22:36:45.497775 134053209202688 model_lib_v2.py:705] Step 2900 per-step time 1.465s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.0002914286,\n",
            " 'Loss/localization_loss': 0.47094655,\n",
            " 'Loss/regularization_loss': 0.13030078,\n",
            " 'Loss/total_loss': 0.6015387,\n",
            " 'learning_rate': 0.07970358}\n",
            "I0427 22:36:45.498364 134053209202688 model_lib_v2.py:708] {'Loss/classification_loss': 0.0002914286,\n",
            " 'Loss/localization_loss': 0.47094655,\n",
            " 'Loss/regularization_loss': 0.13030078,\n",
            " 'Loss/total_loss': 0.6015387,\n",
            " 'learning_rate': 0.07970358}\n",
            "INFO:tensorflow:Step 3000 per-step time 1.507s\n",
            "I0427 22:39:16.162816 134053209202688 model_lib_v2.py:705] Step 3000 per-step time 1.507s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.00065913785,\n",
            " 'Loss/localization_loss': 0.5861965,\n",
            " 'Loss/regularization_loss': 0.12947248,\n",
            " 'Loss/total_loss': 0.7163281,\n",
            " 'learning_rate': 0.0796716}\n",
            "I0427 22:39:16.168538 134053209202688 model_lib_v2.py:708] {'Loss/classification_loss': 0.00065913785,\n",
            " 'Loss/localization_loss': 0.5861965,\n",
            " 'Loss/regularization_loss': 0.12947248,\n",
            " 'Loss/total_loss': 0.7163281,\n",
            " 'learning_rate': 0.0796716}\n",
            "INFO:tensorflow:Step 3100 per-step time 1.599s\n",
            "I0427 22:41:56.079298 134053209202688 model_lib_v2.py:705] Step 3100 per-step time 1.599s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.00036347884,\n",
            " 'Loss/localization_loss': 0.5743248,\n",
            " 'Loss/regularization_loss': 0.12864985,\n",
            " 'Loss/total_loss': 0.70333815,\n",
            " 'learning_rate': 0.07963799}\n",
            "I0427 22:41:56.083575 134053209202688 model_lib_v2.py:708] {'Loss/classification_loss': 0.00036347884,\n",
            " 'Loss/localization_loss': 0.5743248,\n",
            " 'Loss/regularization_loss': 0.12864985,\n",
            " 'Loss/total_loss': 0.70333815,\n",
            " 'learning_rate': 0.07963799}\n",
            "INFO:tensorflow:Step 3200 per-step time 1.498s\n",
            "I0427 22:44:25.898119 134053209202688 model_lib_v2.py:705] Step 3200 per-step time 1.498s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.00039837527,\n",
            " 'Loss/localization_loss': 0.3857256,\n",
            " 'Loss/regularization_loss': 0.12783277,\n",
            " 'Loss/total_loss': 0.5139567,\n",
            " 'learning_rate': 0.07960275}\n",
            "I0427 22:44:25.898671 134053209202688 model_lib_v2.py:708] {'Loss/classification_loss': 0.00039837527,\n",
            " 'Loss/localization_loss': 0.3857256,\n",
            " 'Loss/regularization_loss': 0.12783277,\n",
            " 'Loss/total_loss': 0.5139567,\n",
            " 'learning_rate': 0.07960275}\n",
            "INFO:tensorflow:Step 3300 per-step time 1.553s\n",
            "I0427 22:47:01.175658 134053209202688 model_lib_v2.py:705] Step 3300 per-step time 1.553s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.0002280569,\n",
            " 'Loss/localization_loss': 0.4527958,\n",
            " 'Loss/regularization_loss': 0.12702125,\n",
            " 'Loss/total_loss': 0.5800451,\n",
            " 'learning_rate': 0.07956588}\n",
            "I0427 22:47:01.176310 134053209202688 model_lib_v2.py:708] {'Loss/classification_loss': 0.0002280569,\n",
            " 'Loss/localization_loss': 0.4527958,\n",
            " 'Loss/regularization_loss': 0.12702125,\n",
            " 'Loss/total_loss': 0.5800451,\n",
            " 'learning_rate': 0.07956588}\n",
            "INFO:tensorflow:Step 3400 per-step time 1.648s\n",
            "I0427 22:49:45.995936 134053209202688 model_lib_v2.py:705] Step 3400 per-step time 1.648s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.0005019535,\n",
            " 'Loss/localization_loss': 0.5662264,\n",
            " 'Loss/regularization_loss': 0.12621531,\n",
            " 'Loss/total_loss': 0.69294363,\n",
            " 'learning_rate': 0.079527386}\n",
            "I0427 22:49:45.996605 134053209202688 model_lib_v2.py:708] {'Loss/classification_loss': 0.0005019535,\n",
            " 'Loss/localization_loss': 0.5662264,\n",
            " 'Loss/regularization_loss': 0.12621531,\n",
            " 'Loss/total_loss': 0.69294363,\n",
            " 'learning_rate': 0.079527386}\n",
            "INFO:tensorflow:Step 3500 per-step time 1.424s\n",
            "I0427 22:52:08.358225 134053209202688 model_lib_v2.py:705] Step 3500 per-step time 1.424s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.00029109517,\n",
            " 'Loss/localization_loss': 0.46800688,\n",
            " 'Loss/regularization_loss': 0.125415,\n",
            " 'Loss/total_loss': 0.593713,\n",
            " 'learning_rate': 0.07948727}\n",
            "I0427 22:52:08.358803 134053209202688 model_lib_v2.py:708] {'Loss/classification_loss': 0.00029109517,\n",
            " 'Loss/localization_loss': 0.46800688,\n",
            " 'Loss/regularization_loss': 0.125415,\n",
            " 'Loss/total_loss': 0.593713,\n",
            " 'learning_rate': 0.07948727}\n",
            "INFO:tensorflow:Step 3600 per-step time 1.522s\n",
            "I0427 22:54:40.576491 134053209202688 model_lib_v2.py:705] Step 3600 per-step time 1.522s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.00034043263,\n",
            " 'Loss/localization_loss': 0.72600996,\n",
            " 'Loss/regularization_loss': 0.12462021,\n",
            " 'Loss/total_loss': 0.8509706,\n",
            " 'learning_rate': 0.079445526}\n",
            "I0427 22:54:40.577151 134053209202688 model_lib_v2.py:708] {'Loss/classification_loss': 0.00034043263,\n",
            " 'Loss/localization_loss': 0.72600996,\n",
            " 'Loss/regularization_loss': 0.12462021,\n",
            " 'Loss/total_loss': 0.8509706,\n",
            " 'learning_rate': 0.079445526}\n",
            "INFO:tensorflow:Step 3700 per-step time 1.417s\n",
            "I0427 22:57:02.308421 134053209202688 model_lib_v2.py:705] Step 3700 per-step time 1.417s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.00022779923,\n",
            " 'Loss/localization_loss': 0.48470947,\n",
            " 'Loss/regularization_loss': 0.12383098,\n",
            " 'Loss/total_loss': 0.6087682,\n",
            " 'learning_rate': 0.07940216}\n",
            "I0427 22:57:02.308928 134053209202688 model_lib_v2.py:708] {'Loss/classification_loss': 0.00022779923,\n",
            " 'Loss/localization_loss': 0.48470947,\n",
            " 'Loss/regularization_loss': 0.12383098,\n",
            " 'Loss/total_loss': 0.6087682,\n",
            " 'learning_rate': 0.07940216}\n",
            "INFO:tensorflow:Step 3800 per-step time 1.571s\n",
            "I0427 22:59:39.480745 134053209202688 model_lib_v2.py:705] Step 3800 per-step time 1.571s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.00045666719,\n",
            " 'Loss/localization_loss': 0.48707232,\n",
            " 'Loss/regularization_loss': 0.123047486,\n",
            " 'Loss/total_loss': 0.61057645,\n",
            " 'learning_rate': 0.079357184}\n",
            "I0427 22:59:39.481276 134053209202688 model_lib_v2.py:708] {'Loss/classification_loss': 0.00045666719,\n",
            " 'Loss/localization_loss': 0.48707232,\n",
            " 'Loss/regularization_loss': 0.123047486,\n",
            " 'Loss/total_loss': 0.61057645,\n",
            " 'learning_rate': 0.079357184}\n",
            "INFO:tensorflow:Step 3900 per-step time 1.596s\n",
            "I0427 23:02:19.082989 134053209202688 model_lib_v2.py:705] Step 3900 per-step time 1.596s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.0001923443,\n",
            " 'Loss/localization_loss': 0.40598124,\n",
            " 'Loss/regularization_loss': 0.12227027,\n",
            " 'Loss/total_loss': 0.5284439,\n",
            " 'learning_rate': 0.07931058}\n",
            "I0427 23:02:19.090732 134053209202688 model_lib_v2.py:708] {'Loss/classification_loss': 0.0001923443,\n",
            " 'Loss/localization_loss': 0.40598124,\n",
            " 'Loss/regularization_loss': 0.12227027,\n",
            " 'Loss/total_loss': 0.5284439,\n",
            " 'learning_rate': 0.07931058}\n",
            "INFO:tensorflow:Step 4000 per-step time 1.545s\n",
            "I0427 23:04:53.559625 134053209202688 model_lib_v2.py:705] Step 4000 per-step time 1.545s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.00019510786,\n",
            " 'Loss/localization_loss': 0.4843574,\n",
            " 'Loss/regularization_loss': 0.121500894,\n",
            " 'Loss/total_loss': 0.60605335,\n",
            " 'learning_rate': 0.07926236}\n",
            "I0427 23:04:53.565924 134053209202688 model_lib_v2.py:708] {'Loss/classification_loss': 0.00019510786,\n",
            " 'Loss/localization_loss': 0.4843574,\n",
            " 'Loss/regularization_loss': 0.121500894,\n",
            " 'Loss/total_loss': 0.60605335,\n",
            " 'learning_rate': 0.07926236}\n",
            "INFO:tensorflow:Step 4100 per-step time 1.611s\n",
            "I0427 23:07:34.632416 134053209202688 model_lib_v2.py:705] Step 4100 per-step time 1.611s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.00019104086,\n",
            " 'Loss/localization_loss': 0.55058414,\n",
            " 'Loss/regularization_loss': 0.120743565,\n",
            " 'Loss/total_loss': 0.67151874,\n",
            " 'learning_rate': 0.07921253}\n",
            "I0427 23:07:34.633006 134053209202688 model_lib_v2.py:708] {'Loss/classification_loss': 0.00019104086,\n",
            " 'Loss/localization_loss': 0.55058414,\n",
            " 'Loss/regularization_loss': 0.120743565,\n",
            " 'Loss/total_loss': 0.67151874,\n",
            " 'learning_rate': 0.07921253}\n",
            "INFO:tensorflow:Step 4200 per-step time 1.629s\n",
            "I0427 23:10:17.492119 134053209202688 model_lib_v2.py:705] Step 4200 per-step time 1.629s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.0003470809,\n",
            " 'Loss/localization_loss': 0.5651265,\n",
            " 'Loss/regularization_loss': 0.119990535,\n",
            " 'Loss/total_loss': 0.6854641,\n",
            " 'learning_rate': 0.07916109}\n",
            "I0427 23:10:17.492745 134053209202688 model_lib_v2.py:708] {'Loss/classification_loss': 0.0003470809,\n",
            " 'Loss/localization_loss': 0.5651265,\n",
            " 'Loss/regularization_loss': 0.119990535,\n",
            " 'Loss/total_loss': 0.6854641,\n",
            " 'learning_rate': 0.07916109}\n",
            "^C\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python object_detection/exporter_main_v2.py --trained_checkpoint_dir=./ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8/model.ckpt --output_directory=inference_graph --pipeline_config_path=./model/ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8/pipeline.config"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e0ucfd_Z2_eq",
        "outputId": "f5f56b65-d057-4ca7-bf22-006c4ee70269"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2024-04-27 23:20:20.729044: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
            "2024-04-27 23:20:21.732965: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
            "2024-04-27 23:20:21.735277: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2024-04-27 23:20:24.841008: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.10/dist-packages/tensorflow/python/autograph/impl/api.py:459: calling map_fn_v2 (from tensorflow.python.ops.map_fn) with back_prop=False is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "back_prop=False is deprecated. Consider using tf.stop_gradient instead.\n",
            "Instead of:\n",
            "results = tf.map_fn(fn, elems, back_prop=False)\n",
            "Use:\n",
            "results = tf.nest.map_structure(tf.stop_gradient, tf.map_fn(fn, elems))\n",
            "W0427 23:20:33.449589 137935092449280 deprecation.py:641] From /usr/local/lib/python3.10/dist-packages/tensorflow/python/autograph/impl/api.py:459: calling map_fn_v2 (from tensorflow.python.ops.map_fn) with back_prop=False is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "back_prop=False is deprecated. Consider using tf.stop_gradient instead.\n",
            "Instead of:\n",
            "results = tf.map_fn(fn, elems, back_prop=False)\n",
            "Use:\n",
            "results = tf.nest.map_structure(tf.stop_gradient, tf.map_fn(fn, elems))\n",
            "I0427 23:20:38.966172 137935092449280 api.py:460] feature_map_spatial_dims: [(40, 40), (20, 20), (10, 10), (5, 5), (3, 3)]\n",
            "I0427 23:20:50.241478 137935092449280 api.py:460] feature_map_spatial_dims: [(40, 40), (20, 20), (10, 10), (5, 5), (3, 3)]\n",
            "I0427 23:20:53.584429 137935092449280 signature_serialization.py:148] Function `call_func` contains input name(s) resource with unsupported characters which will be renamed to weightsharedconvolutionalboxpredictor_predictiontower_conv2d_3_batchnorm_feature_4_fusedbatchnormv3_readvariableop_1_resource in the SavedModel.\n",
            "I0427 23:20:55.059622 137935092449280 api.py:460] feature_map_spatial_dims: [(40, 40), (20, 20), (10, 10), (5, 5), (3, 3)]\n",
            "WARNING:tensorflow:Skipping full serialization of Keras layer <object_detection.meta_architectures.ssd_meta_arch.SSDMetaArch object at 0x7d73114cd600>, because it is not built.\n",
            "W0427 23:20:57.576225 137935092449280 save_impl.py:66] Skipping full serialization of Keras layer <object_detection.meta_architectures.ssd_meta_arch.SSDMetaArch object at 0x7d73114cd600>, because it is not built.\n",
            "WARNING:tensorflow:Skipping full serialization of Keras layer <keras.src.layers.convolutional.separable_conv2d.SeparableConv2D object at 0x7d73024c3730>, because it is not built.\n",
            "W0427 23:20:57.920588 137935092449280 save_impl.py:66] Skipping full serialization of Keras layer <keras.src.layers.convolutional.separable_conv2d.SeparableConv2D object at 0x7d73024c3730>, because it is not built.\n",
            "WARNING:tensorflow:Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7d73022f1510>, because it is not built.\n",
            "W0427 23:20:57.920911 137935092449280 save_impl.py:66] Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7d73022f1510>, because it is not built.\n",
            "WARNING:tensorflow:Skipping full serialization of Keras layer <keras.src.layers.core.lambda_layer.Lambda object at 0x7d73022f1090>, because it is not built.\n",
            "W0427 23:20:57.921046 137935092449280 save_impl.py:66] Skipping full serialization of Keras layer <keras.src.layers.core.lambda_layer.Lambda object at 0x7d73022f1090>, because it is not built.\n",
            "WARNING:tensorflow:Skipping full serialization of Keras layer <keras.src.layers.convolutional.separable_conv2d.SeparableConv2D object at 0x7d73022f1e40>, because it is not built.\n",
            "W0427 23:20:57.921183 137935092449280 save_impl.py:66] Skipping full serialization of Keras layer <keras.src.layers.convolutional.separable_conv2d.SeparableConv2D object at 0x7d73022f1e40>, because it is not built.\n",
            "WARNING:tensorflow:Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7d73022f19f0>, because it is not built.\n",
            "W0427 23:20:57.921296 137935092449280 save_impl.py:66] Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7d73022f19f0>, because it is not built.\n",
            "WARNING:tensorflow:Skipping full serialization of Keras layer <keras.src.layers.core.lambda_layer.Lambda object at 0x7d73022f2dd0>, because it is not built.\n",
            "W0427 23:20:57.921396 137935092449280 save_impl.py:66] Skipping full serialization of Keras layer <keras.src.layers.core.lambda_layer.Lambda object at 0x7d73022f2dd0>, because it is not built.\n",
            "WARNING:tensorflow:Skipping full serialization of Keras layer <keras.src.layers.convolutional.separable_conv2d.SeparableConv2D object at 0x7d73022f2650>, because it is not built.\n",
            "W0427 23:20:57.921491 137935092449280 save_impl.py:66] Skipping full serialization of Keras layer <keras.src.layers.convolutional.separable_conv2d.SeparableConv2D object at 0x7d73022f2650>, because it is not built.\n",
            "WARNING:tensorflow:Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7d73022f2110>, because it is not built.\n",
            "W0427 23:20:57.921585 137935092449280 save_impl.py:66] Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7d73022f2110>, because it is not built.\n",
            "WARNING:tensorflow:Skipping full serialization of Keras layer <keras.src.layers.core.lambda_layer.Lambda object at 0x7d73022f06d0>, because it is not built.\n",
            "W0427 23:20:57.921678 137935092449280 save_impl.py:66] Skipping full serialization of Keras layer <keras.src.layers.core.lambda_layer.Lambda object at 0x7d73022f06d0>, because it is not built.\n",
            "WARNING:tensorflow:Skipping full serialization of Keras layer <keras.src.layers.convolutional.separable_conv2d.SeparableConv2D object at 0x7d73022f1ff0>, because it is not built.\n",
            "W0427 23:20:57.921770 137935092449280 save_impl.py:66] Skipping full serialization of Keras layer <keras.src.layers.convolutional.separable_conv2d.SeparableConv2D object at 0x7d73022f1ff0>, because it is not built.\n",
            "WARNING:tensorflow:Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7d73022f2a70>, because it is not built.\n",
            "W0427 23:20:57.921861 137935092449280 save_impl.py:66] Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7d73022f2a70>, because it is not built.\n",
            "WARNING:tensorflow:Skipping full serialization of Keras layer <keras.src.layers.core.lambda_layer.Lambda object at 0x7d73022f2080>, because it is not built.\n",
            "W0427 23:20:57.921960 137935092449280 save_impl.py:66] Skipping full serialization of Keras layer <keras.src.layers.core.lambda_layer.Lambda object at 0x7d73022f2080>, because it is not built.\n",
            "WARNING:tensorflow:Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7d7302439c90>, because it is not built.\n",
            "W0427 23:20:57.922057 137935092449280 save_impl.py:66] Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7d7302439c90>, because it is not built.\n",
            "WARNING:tensorflow:Skipping full serialization of Keras layer <keras.src.layers.core.lambda_layer.Lambda object at 0x7d731029e590>, because it is not built.\n",
            "W0427 23:20:57.922164 137935092449280 save_impl.py:66] Skipping full serialization of Keras layer <keras.src.layers.core.lambda_layer.Lambda object at 0x7d731029e590>, because it is not built.\n",
            "WARNING:tensorflow:Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7d730277f130>, because it is not built.\n",
            "W0427 23:20:57.922273 137935092449280 save_impl.py:66] Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7d730277f130>, because it is not built.\n",
            "WARNING:tensorflow:Skipping full serialization of Keras layer <keras.src.layers.core.lambda_layer.Lambda object at 0x7d7310274130>, because it is not built.\n",
            "W0427 23:20:57.922367 137935092449280 save_impl.py:66] Skipping full serialization of Keras layer <keras.src.layers.core.lambda_layer.Lambda object at 0x7d7310274130>, because it is not built.\n",
            "WARNING:tensorflow:Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7d7310276440>, because it is not built.\n",
            "W0427 23:20:57.922461 137935092449280 save_impl.py:66] Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7d7310276440>, because it is not built.\n",
            "WARNING:tensorflow:Skipping full serialization of Keras layer <keras.src.layers.core.lambda_layer.Lambda object at 0x7d7310275390>, because it is not built.\n",
            "W0427 23:20:57.922555 137935092449280 save_impl.py:66] Skipping full serialization of Keras layer <keras.src.layers.core.lambda_layer.Lambda object at 0x7d7310275390>, because it is not built.\n",
            "WARNING:tensorflow:Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7d7310276740>, because it is not built.\n",
            "W0427 23:20:57.922657 137935092449280 save_impl.py:66] Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7d7310276740>, because it is not built.\n",
            "WARNING:tensorflow:Skipping full serialization of Keras layer <keras.src.layers.core.lambda_layer.Lambda object at 0x7d7310274940>, because it is not built.\n",
            "W0427 23:20:57.922748 137935092449280 save_impl.py:66] Skipping full serialization of Keras layer <keras.src.layers.core.lambda_layer.Lambda object at 0x7d7310274940>, because it is not built.\n",
            "WARNING:tensorflow:Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7d73102757e0>, because it is not built.\n",
            "W0427 23:20:57.922840 137935092449280 save_impl.py:66] Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7d73102757e0>, because it is not built.\n",
            "WARNING:tensorflow:Skipping full serialization of Keras layer <keras.src.layers.core.lambda_layer.Lambda object at 0x7d73022e71c0>, because it is not built.\n",
            "W0427 23:20:57.922933 137935092449280 save_impl.py:66] Skipping full serialization of Keras layer <keras.src.layers.core.lambda_layer.Lambda object at 0x7d73022e71c0>, because it is not built.\n",
            "WARNING:tensorflow:Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7d73022e6890>, because it is not built.\n",
            "W0427 23:20:57.923026 137935092449280 save_impl.py:66] Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7d73022e6890>, because it is not built.\n",
            "WARNING:tensorflow:Skipping full serialization of Keras layer <keras.src.layers.core.lambda_layer.Lambda object at 0x7d73022e6020>, because it is not built.\n",
            "W0427 23:20:57.923139 137935092449280 save_impl.py:66] Skipping full serialization of Keras layer <keras.src.layers.core.lambda_layer.Lambda object at 0x7d73022e6020>, because it is not built.\n",
            "WARNING:tensorflow:Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7d73022e4e20>, because it is not built.\n",
            "W0427 23:20:57.923244 137935092449280 save_impl.py:66] Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7d73022e4e20>, because it is not built.\n",
            "WARNING:tensorflow:Skipping full serialization of Keras layer <keras.src.layers.core.lambda_layer.Lambda object at 0x7d73022e6da0>, because it is not built.\n",
            "W0427 23:20:57.923343 137935092449280 save_impl.py:66] Skipping full serialization of Keras layer <keras.src.layers.core.lambda_layer.Lambda object at 0x7d73022e6da0>, because it is not built.\n",
            "WARNING:tensorflow:Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7d73022e6c20>, because it is not built.\n",
            "W0427 23:20:57.923436 137935092449280 save_impl.py:66] Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7d73022e6c20>, because it is not built.\n",
            "WARNING:tensorflow:Skipping full serialization of Keras layer <keras.src.layers.core.lambda_layer.Lambda object at 0x7d73022e7d60>, because it is not built.\n",
            "W0427 23:20:57.923550 137935092449280 save_impl.py:66] Skipping full serialization of Keras layer <keras.src.layers.core.lambda_layer.Lambda object at 0x7d73022e7d60>, because it is not built.\n",
            "WARNING:tensorflow:Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7d73022e5090>, because it is not built.\n",
            "W0427 23:20:57.923644 137935092449280 save_impl.py:66] Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7d73022e5090>, because it is not built.\n",
            "WARNING:tensorflow:Skipping full serialization of Keras layer <keras.src.layers.core.lambda_layer.Lambda object at 0x7d73022e72e0>, because it is not built.\n",
            "W0427 23:20:57.923740 137935092449280 save_impl.py:66] Skipping full serialization of Keras layer <keras.src.layers.core.lambda_layer.Lambda object at 0x7d73022e72e0>, because it is not built.\n",
            "WARNING:tensorflow:Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7d73022e60b0>, because it is not built.\n",
            "W0427 23:20:57.923832 137935092449280 save_impl.py:66] Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7d73022e60b0>, because it is not built.\n",
            "WARNING:tensorflow:Skipping full serialization of Keras layer <keras.src.layers.core.lambda_layer.Lambda object at 0x7d73027aa170>, because it is not built.\n",
            "W0427 23:20:57.923925 137935092449280 save_impl.py:66] Skipping full serialization of Keras layer <keras.src.layers.core.lambda_layer.Lambda object at 0x7d73027aa170>, because it is not built.\n",
            "WARNING:tensorflow:Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7d73027aa0e0>, because it is not built.\n",
            "W0427 23:20:57.924016 137935092449280 save_impl.py:66] Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7d73027aa0e0>, because it is not built.\n",
            "WARNING:tensorflow:Skipping full serialization of Keras layer <keras.src.layers.core.lambda_layer.Lambda object at 0x7d73027a9b40>, because it is not built.\n",
            "W0427 23:20:57.924128 137935092449280 save_impl.py:66] Skipping full serialization of Keras layer <keras.src.layers.core.lambda_layer.Lambda object at 0x7d73027a9b40>, because it is not built.\n",
            "WARNING:tensorflow:Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7d73027ab0a0>, because it is not built.\n",
            "W0427 23:20:57.924231 137935092449280 save_impl.py:66] Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7d73027ab0a0>, because it is not built.\n",
            "WARNING:tensorflow:Skipping full serialization of Keras layer <keras.src.layers.core.lambda_layer.Lambda object at 0x7d73027abf40>, because it is not built.\n",
            "W0427 23:20:57.924335 137935092449280 save_impl.py:66] Skipping full serialization of Keras layer <keras.src.layers.core.lambda_layer.Lambda object at 0x7d73027abf40>, because it is not built.\n",
            "WARNING:tensorflow:Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7d731028ee90>, because it is not built.\n",
            "W0427 23:20:57.924431 137935092449280 save_impl.py:66] Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7d731028ee90>, because it is not built.\n",
            "WARNING:tensorflow:Skipping full serialization of Keras layer <keras.src.layers.core.lambda_layer.Lambda object at 0x7d730272f3a0>, because it is not built.\n",
            "W0427 23:20:57.924524 137935092449280 save_impl.py:66] Skipping full serialization of Keras layer <keras.src.layers.core.lambda_layer.Lambda object at 0x7d730272f3a0>, because it is not built.\n",
            "WARNING:tensorflow:Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7d730272c610>, because it is not built.\n",
            "W0427 23:20:57.924618 137935092449280 save_impl.py:66] Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7d730272c610>, because it is not built.\n",
            "WARNING:tensorflow:Skipping full serialization of Keras layer <keras.src.layers.core.lambda_layer.Lambda object at 0x7d730272fac0>, because it is not built.\n",
            "W0427 23:20:57.924712 137935092449280 save_impl.py:66] Skipping full serialization of Keras layer <keras.src.layers.core.lambda_layer.Lambda object at 0x7d730272fac0>, because it is not built.\n",
            "WARNING:tensorflow:Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7d7302751f60>, because it is not built.\n",
            "W0427 23:20:57.924818 137935092449280 save_impl.py:66] Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7d7302751f60>, because it is not built.\n",
            "WARNING:tensorflow:Skipping full serialization of Keras layer <keras.src.layers.core.lambda_layer.Lambda object at 0x7d7302750040>, because it is not built.\n",
            "W0427 23:20:57.924915 137935092449280 save_impl.py:66] Skipping full serialization of Keras layer <keras.src.layers.core.lambda_layer.Lambda object at 0x7d7302750040>, because it is not built.\n",
            "WARNING:tensorflow:Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7d7302750c40>, because it is not built.\n",
            "W0427 23:20:57.925008 137935092449280 save_impl.py:66] Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7d7302750c40>, because it is not built.\n",
            "WARNING:tensorflow:Skipping full serialization of Keras layer <keras.src.layers.core.lambda_layer.Lambda object at 0x7d7302752d10>, because it is not built.\n",
            "W0427 23:20:57.990583 137935092449280 save_impl.py:66] Skipping full serialization of Keras layer <keras.src.layers.core.lambda_layer.Lambda object at 0x7d7302752d10>, because it is not built.\n",
            "I0427 23:21:13.585406 137935092449280 save.py:274] Found untraced functions such as WeightSharedConvolutionalBoxPredictor_layer_call_fn, WeightSharedConvolutionalBoxPredictor_layer_call_and_return_conditional_losses, WeightSharedConvolutionalBoxHead_layer_call_fn, WeightSharedConvolutionalBoxHead_layer_call_and_return_conditional_losses, WeightSharedConvolutionalClassHead_layer_call_fn while saving (showing 5 of 173). These functions will not be directly callable after loading.\n",
            "INFO:tensorflow:Assets written to: inference_graph/saved_model/assets\n",
            "I0427 23:21:20.651581 137935092449280 builder_impl.py:804] Assets written to: inference_graph/saved_model/assets\n",
            "I0427 23:21:20.981827 137935092449280 fingerprinting_utils.py:48] Writing fingerprint to inference_graph/saved_model/fingerprint.pb\n",
            "INFO:tensorflow:Writing pipeline config file to inference_graph/pipeline.config\n",
            "I0427 23:21:21.639619 137935092449280 config_util.py:253] Writing pipeline config file to inference_graph/pipeline.config\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "!zip -r new_model.zip ./inference_graph/\n",
        "files.download(f'new_model.zip')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 243
        },
        "id": "krpAybjm3lTK",
        "outputId": "fccec051-8ca5-4b21-d4cb-85b409e7a932"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  adding: inference_graph/ (stored 0%)\n",
            "  adding: inference_graph/saved_model/ (stored 0%)\n",
            "  adding: inference_graph/saved_model/assets/ (stored 0%)\n",
            "  adding: inference_graph/saved_model/variables/ (stored 0%)\n",
            "  adding: inference_graph/saved_model/variables/variables.data-00000-of-00001 (deflated 9%)\n",
            "  adding: inference_graph/saved_model/variables/variables.index (deflated 79%)\n",
            "  adding: inference_graph/saved_model/saved_model.pb (deflated 92%)\n",
            "  adding: inference_graph/saved_model/fingerprint.pb (stored 0%)\n",
            "  adding: inference_graph/pipeline.config (deflated 69%)\n",
            "  adding: inference_graph/checkpoint/ (stored 0%)\n",
            "  adding: inference_graph/checkpoint/ckpt-0.data-00000-of-00001 (deflated 8%)\n",
            "  adding: inference_graph/checkpoint/ckpt-0.index (deflated 81%)\n",
            "  adding: inference_graph/checkpoint/checkpoint (deflated 41%)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_6100db1a-36a3-436f-a23d-d78cff97945c\", \"new_model.zip\", 19781077)"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!cd ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8 && rm -rf model.ckpt"
      ],
      "metadata": {
        "id": "X0Wr0-gpHI4d"
      },
      "execution_count": 5,
      "outputs": []
    }
  ]
}